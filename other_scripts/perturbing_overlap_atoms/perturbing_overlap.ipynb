{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding code to the pythonpath...\n",
      "[Errno 2] No such file or directory: '/home/anna/anaconda3/envs/biosimspace-dev/bin/pmemd.cuda'\n",
      "could not determine AMBER version.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning on use of the timeseries module: If the inherent timescales of the system are long compared to those being analyzed, this statistical inefficiency may be an underestimate.  The estimate presumes the use of many statistically independent samples.  Tests should be performed to assess whether this condition is satisfied.   Be cautious in the interpretation of the data.\n",
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n",
      "/home/anna/anaconda3/envs/biosimspace-dev/lib/python3.9/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================\n",
      "Sending anonymous Sire usage statistics to http://siremol.org.\n",
      "For more information, see http://siremol.org/analytics\n",
      "To disable, set the environment variable 'SIRE_DONT_PHONEHOME' to 1\n",
      "To see the information sent, set the environment variable \n",
      "SIRE_VERBOSE_PHONEHOME equal to 1. To silence this message, set\n",
      "the environment variable SIRE_SILENT_PHONEHOME to 1.\n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem as sem\n",
    "import glob\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import itertools as it\n",
    "\n",
    "print(\"adding code to the pythonpath...\")\n",
    "code = \"/home/anna/Documents/code/python\"\n",
    "if code not in sys.path:\n",
    "    sys.path.insert(1, code)\n",
    "import pipeline\n",
    "from pipeline.utils import validate\n",
    "from pipeline import *\n",
    "from pipeline.utils import validate\n",
    "from pipeline.analysis import *\n",
    "\n",
    "if \"/home/anna/Documents/cinnabar\" not in sys.path:\n",
    "    sys.path.insert(1, \"/home/anna/Documents/cinnabar\")\n",
    "import cinnabar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine\n",
    "eng = \"GROMACS\"\n",
    "\n",
    "# failed perturbations\n",
    "failed_perts = []\n",
    "\n",
    "for protein in [\"tyk2\", \"mcl1\", \"p38\"]:\n",
    "    bench_folder = f\"/home/anna/Documents/benchmark\"\n",
    "    main_dir = f\"{bench_folder}/extracted/{protein}\"\n",
    "    # main_dir = f\"/backup/42_reruns/{protein}\"\n",
    "\n",
    "    # choose location for the files\n",
    "    net_file = f\"{main_dir}/execution_model/network_combined.dat\"\n",
    "    ana_file = f\"{main_dir}/execution_model/analysis_protocol.dat\"\n",
    "    exp_file = f\"{bench_folder}/inputs/experimental/{protein}.yml\"\n",
    "\n",
    "    # if os.path.exists(f\"{main_dir}/outputs_extracted/results\"):\n",
    "    #     results_folder = f\"{main_dir}/outputs_extracted/results\"\n",
    "    # elif os.path.exists(f\"{main_dir}/outputs/results\"):\n",
    "    #     results_folder = f\"{main_dir}/outputs/results\"\n",
    "    # else:\n",
    "    #     raise ValueError(\n",
    "    #         f\"results directory not found in the {main_dir}. please make sure results were written using the analysis script previously in the pipeline\"\n",
    "    #     )\n",
    "    results_folder = f\"{main_dir}/outputs_extracted/results\"\n",
    "    output_folder = validate.folder_path(f\"{main_dir}/analysis\", create=True)\n",
    "    all_analysis_object = analysis_network(\n",
    "        results_folder,\n",
    "        exp_file=exp_file,\n",
    "        net_file=net_file,\n",
    "        output_folder=output_folder,\n",
    "        analysis_prot=ana_file,\n",
    "        # method = \"updated\",\n",
    "        engines=eng,\n",
    "    )\n",
    "\n",
    "    # can add any other results files\n",
    "    # all_analysis_object.compute_other_results(file_name=None, name=None)\n",
    "    all_analysis_object.compute_results(use_cinnabar=True)\n",
    "    # check if there are any failed perturbations\n",
    "    failed_perts.append(all_analysis_object.failed_runs(eng))\n",
    "\n",
    "# flatten perts\n",
    "failed_perts = [item for row in failed_perts for item in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = \"/home/anna/Documents/benchmark\"\n",
    "\n",
    "df_dict = {}\n",
    "\n",
    "for prot in [\"tyk2\", \"mcl1\", \"p38\"]:\n",
    "    file = f\"{main_folder}/extracted/{prot}/perturbing_overlap.dat\"\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"score\"] = np.nan\n",
    "\n",
    "    perturbations, ligs = pipeline.analysis.get_info_network(\n",
    "        f\"{main_folder}/{prot}_benchmark/execution_model/network_combined.dat\"\n",
    "    )\n",
    "\n",
    "    # # write lomap scores for all of the network\n",
    "    # pl = pipeline.setup.initialise_pipeline()\n",
    "    # # where the ligands for the pipeline are located. These should all be in the same folder in sdf format\n",
    "    # pl.ligands_folder(f\"{main_folder}/inputs/{prot}/ligands\")\n",
    "    # pl.main_folder(f\"{main_folder}/{prot}_benchmark\")\n",
    "    # pl.setup_ligands(file_name=f\"{main_folder}/{prot}_benchmark/execution_model/combined/ligands.dat\")\n",
    "    # pl.setup_network(folder=\"combined\")\n",
    "    # for pert in pl.perturbations:\n",
    "    #     pl.remove_perturbation(pert)\n",
    "    # for pert in perturbations:\n",
    "    #     pl.add_perturbation(pert)\n",
    "\n",
    "    # read in all the lomap scores\n",
    "    score_dict = {}\n",
    "    with open(\n",
    "        f\"{main_folder}/{prot}_benchmark/execution_model/network_scores.dat\"\n",
    "    ) as lfile:\n",
    "        for line in lfile:\n",
    "            score_dict[\n",
    "                f\"{line.split(',')[0].strip()}~{line.split(',')[1].strip()}\"\n",
    "            ] = float(line.split(\",\")[-1].strip())\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"perturbation\"] not in perturbations:\n",
    "            df = df.drop(index)\n",
    "        else:\n",
    "            df.at[index, \"score\"] = score_dict[row[\"perturbation\"]]\n",
    "\n",
    "    df_dict[prot] = df\n",
    "\n",
    "frames = []\n",
    "for key in df_dict.keys():\n",
    "    frames.append(df_dict[key])\n",
    "\n",
    "all_df = pd.concat(frames)\n",
    "df = all_df\n",
    "# df = df_dict[\"p38\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = df[df[\"engine\"].isin([eng])]\n",
    "new_df_failed = df_eng[df_eng[\"perturbation\"].isin(failed_perts)]\n",
    "new_df_not_failed = df_eng[~df_eng[\"perturbation\"].isin(failed_perts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_lomap_score_avg = np.average(new_df_failed[\"score\"])\n",
    "not_failed_lomap_score_avg = np.average(new_df_not_failed[\"score\"])\n",
    "print(\n",
    "    f\"avg score of failed is {failed_lomap_score_avg} and not failed avg score is {not_failed_lomap_score_avg}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of failed run in terms of perturbing atoms\n",
    "\n",
    "df_has = df[df[\"percen_overlap_okay\"] >= 0]\n",
    "df_none = (\n",
    "    pd.merge(df_has, df, how=\"outer\", indicator=True)\n",
    "    .query(\"_merge != 'both'\")\n",
    "    .drop(\"_merge\", axis=1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(len(df_none))\n",
    "df_none[\"perturbing_atoms\"].plot.hist(bins=10)\n",
    "plt.xlabel(\"perturbing atoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.dropna()\n",
    "\n",
    "df_plot.plot.scatter(\"score\", \"too_small_avg\", c=\"perturbing_atoms\", colormap=\"viridis\")\n",
    "# plt.title(f\"\")\n",
    "# plt.xlabel(\"lomap score\")\n",
    "# plt.ylabel(\"average no. of too small off-diagonals per leg\")\n",
    "\n",
    "df_plot.plot.scatter(\n",
    "    \"score\", \"percen_overlap_okay\", c=\"perturbing_atoms\", colormap=\"viridis\"\n",
    ")\n",
    "# plt.title(f\"\")\n",
    "# plt.xlabel(\"lomap score\")\n",
    "# plt.ylabel(\"percentage of okay overlap\")\n",
    "# )\n",
    "\n",
    "df_plot.plot.scatter(\"score\", \"perturbing_atoms\", c=\"too_small_avg\", colormap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting logarithmically\n",
    "df_plot = df.dropna()\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.scatter(df_plot[\"score\"], df_plot[\"too_small_avg\"], c=df_plot[\"perturbing_atoms\"])\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"perturbing_atoms\")\n",
    "plt.ylabel(\"too_small_avg\")\n",
    "plt.xlabel(\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting logarithmically\n",
    "df_plot = df.dropna()\n",
    "\n",
    "# plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.scatter(\n",
    "    df_plot[\"perturbing_atoms\"],\n",
    "    df_plot[\"too_small_avg\"],\n",
    "    c=df_plot[\"percen_overlap_okay\"],\n",
    ")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"percen_overlap_okay\")\n",
    "plt.ylabel(\"too_small_avg\")\n",
    "plt.xlabel(\"perturbing_atoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting logarithmically\n",
    "df_plot = df.dropna()\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.scatter(\n",
    "    df_plot[\"perturbing_atoms\"],\n",
    "    df_plot[\"percen_overlap_okay\"],\n",
    "    c=df_plot[\"too_small_avg\"],\n",
    ")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"too_small_avg\")\n",
    "plt.ylabel(\"percen_overlap_okay\")\n",
    "plt.xlabel(\"perturbing_atoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting logarithmically\n",
    "df_plot = df.dropna()\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.scatter(\n",
    "    df_plot[\"perturbing_atoms\"], df_plot[\"diff_to_exp\"], c=df_plot[\"too_small_avg\"]\n",
    ")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"too_small_avg\")\n",
    "plt.ylabel(\"diff_to_exp\")\n",
    "plt.xlabel(\"perturbing_atoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.dropna()\n",
    "\n",
    "df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"percen_overlap_okay\", c=\"too_small_avg\", colormap=\"viridis\"\n",
    ")\n",
    "# plt.title(f\"\")\n",
    "# plt.xlabel(\"no. of perturbing atoms\")\n",
    "# plt.ylabel(\"percentage of okay overlap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"too_small_avg\", c=\"percen_overlap_okay\", colormap=\"viridis\"\n",
    ")\n",
    "# plt.title(f\"\")\n",
    "# plt.xlabel(\"no. of perturbing atoms\")\n",
    "# plt.ylabel(\"average no. of too small off-diagonals per leg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot.plot.scatter(\n",
    "    \"percen_overlap_okay\", \"too_small_avg\", c=\"perturbing_atoms\", colormap=\"viridis\"\n",
    ")\n",
    "# plt.title(f\"\")\n",
    "# plt.xlabel(\"percentage of okay overlap\")\n",
    "# plt.ylabel(\"average no. of too small off-diagonals per leg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude outliers as needed\n",
    "df3 = df_plot[df_plot[\"diff_to_exp\"] >= 20]\n",
    "df_out = (\n",
    "    pd.merge(df3, df_plot, how=\"outer\", indicator=True)\n",
    "    .query(\"_merge != 'both'\")\n",
    "    .drop(\"_merge\", axis=1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# df_out = df_plot\n",
    "\n",
    "df_out.plot.scatter(\n",
    "    \"perturbing_atoms\", \"diff_to_exp\", c=\"percen_overlap_okay\", colormap=\"viridis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"perturbing_atoms\", \"percen_overlap_okay\", \"too_small_avg\"]\n",
    "bins = [6, 3, 5]\n",
    "for column, bin in zip(columns, bins):\n",
    "    fig = plt.figure()\n",
    "    df_plot = df[column]\n",
    "    df_plot.plot.hist(subplots=True, bins=bin)\n",
    "    plt.title(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for per engine\n",
    "eng = \"GROMACS\"\n",
    "df2 = df[df[\"engine\"] == eng]\n",
    "df_plot = df2.dropna()\n",
    "df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"percen_overlap_okay\", c=\"too_small_avg\", colormap=\"viridis\"\n",
    ")\n",
    "df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"too_small_avg\", c=\"percen_overlap_okay\", colormap=\"viridis\"\n",
    ")\n",
    "df_plot.plot.scatter(\n",
    "    \"percen_overlap_okay\", \"too_small_avg\", c=\"perturbing_atoms\", colormap=\"viridis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engs = [\"AMBER\", \"SOMD\", \"GROMACS\"]\n",
    "eng_dict = {}\n",
    "\n",
    "col_dict = pipeline.analysis.plotting_engines.set_colours()\n",
    "\n",
    "for eng in engs:\n",
    "    df2 = df[df[\"engine\"] == eng]\n",
    "    eng_dict[eng] = df2\n",
    "\n",
    "for eng in engs:\n",
    "    df_plot = eng_dict[eng].dropna()\n",
    "    ax = df_plot.plot.scatter(\n",
    "        \"perturbing_atoms\", \"percen_overlap_okay\", c=col_dict[eng]\n",
    "    )\n",
    "\n",
    "df_plot = eng_dict[\"AMBER\"].dropna()\n",
    "ax1 = df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"percen_overlap_okay\", c=col_dict[\"AMBER\"]\n",
    ")\n",
    "df_plot = eng_dict[\"SOMD\"].dropna()\n",
    "ax2 = df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"percen_overlap_okay\", c=col_dict[\"SOMD\"], ax=ax1\n",
    ")\n",
    "df_plot = eng_dict[\"GROMACS\"].dropna()\n",
    "ax3 = df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"percen_overlap_okay\", c=col_dict[\"GROMACS\"], ax=ax1\n",
    ")\n",
    "plt.legend(col_dict, loc=\"upper right\")\n",
    "print(ax1 == ax2 == ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engs = [\"AMBER\", \"SOMD\", \"GROMACS\"]\n",
    "eng_dict = {}\n",
    "\n",
    "col_dict = pipeline.analysis.plotting_engines.set_colours()\n",
    "\n",
    "for eng in engs:\n",
    "    df2 = df[df[\"engine\"] == eng]\n",
    "    df3 = df2[df2[\"diff_to_exp\"] >= 5]\n",
    "    df4 = (\n",
    "        pd.merge(df3, df2, how=\"outer\", indicator=True)\n",
    "        .query(\"_merge != 'both'\")\n",
    "        .drop(\"_merge\", axis=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    eng_dict[eng] = df4\n",
    "\n",
    "for eng in engs:\n",
    "    df_plot = eng_dict[eng].dropna()\n",
    "    ax = df_plot.plot.scatter(\"perturbing_atoms\", \"diff_to_exp\", c=col_dict[eng])\n",
    "\n",
    "df_plot = eng_dict[\"AMBER\"].dropna()\n",
    "ax1 = df_plot.plot.scatter(\"perturbing_atoms\", \"diff_to_exp\", c=col_dict[\"AMBER\"])\n",
    "df_plot = eng_dict[\"SOMD\"].dropna()\n",
    "ax2 = df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"diff_to_exp\", c=col_dict[\"SOMD\"], ax=ax1\n",
    ")\n",
    "df_plot = eng_dict[\"GROMACS\"].dropna()\n",
    "ax3 = df_plot.plot.scatter(\n",
    "    \"perturbing_atoms\", \"diff_to_exp\", c=col_dict[\"GROMACS\"], ax=ax1\n",
    ")\n",
    "plt.legend(col_dict, loc=\"upper right\")\n",
    "print(ax1 == ax2 == ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking which perts are bad overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"{main_folder}/extracted/mcl1/perturbing_overlap.dat\"\n",
    "\n",
    "eng_dict_ok = {\"AMBER\": None, \"SOMD\": None, \"GROMACS\": None}\n",
    "eng_dict_not = {\"AMBER\": None, \"SOMD\": None, \"GROMACS\": None}\n",
    "\n",
    "for engine in [\"SOMD\", \"AMBER\", \"GROMACS\"]:\n",
    "    print(engine)\n",
    "    perts_okay = []\n",
    "    perts_not = []\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            pert = line.split(\",\")[0].strip()\n",
    "            overlap_okay = line.split(\",\")[3].strip()\n",
    "            eng = line.split(\",\")[1].strip()\n",
    "\n",
    "            if eng == engine:\n",
    "                if overlap_okay == \"100.0\":  #  or overlap_okay == \"50.0\"\n",
    "                    if pert not in perts_okay:\n",
    "                        perts_okay.append(pert)\n",
    "                else:\n",
    "                    if pert not in perts_not:\n",
    "                        perts_not.append(pert)\n",
    "\n",
    "    # for pert in perts_not:\n",
    "    #     if pert in perts_okay:\n",
    "    #         perts_okay.remove(pert)\n",
    "\n",
    "    print(len(perts_okay))\n",
    "    print(perts_okay)\n",
    "    print(len(perts_not))\n",
    "    print(perts_not)\n",
    "    print(\" \")\n",
    "\n",
    "    eng_dict_ok[engine] = perts_okay\n",
    "    eng_dict_not[engine] = perts_not\n",
    "\n",
    "\n",
    "both_perts = []\n",
    "\n",
    "for pert in eng_dict_ok[\"AMBER\"]:\n",
    "    if pert in eng_dict_ok[\"SOMD\"]:\n",
    "        both_perts.append(pert)\n",
    "\n",
    "print(len(both_perts))\n",
    "print(both_perts)\n",
    "print(\" \")\n",
    "\n",
    "all_perts = eng_dict_ok[\"SOMD\"] + eng_dict_not[\"SOMD\"]\n",
    "not_okay = []\n",
    "for pert in all_perts:\n",
    "    if pert not in both_perts:\n",
    "        not_okay.append(pert)\n",
    "\n",
    "print(len(not_okay))\n",
    "print(not_okay)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot = pipeline_protocol()\n",
    "prot.num_lambda(16)\n",
    "pert_dict = {(pert.split(\"~\")[0], pert.split(\"~\")[1]): \"None\" for pert in not_okay}\n",
    "write_network(pert_dict, prot, \"new_mcl1_network_both2.dat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
