{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis script for results in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import sem as sem\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "if \"/home/anna/Documents/cinnabar\" not in sys.path:\n",
    "    sys.path.insert(1, \"/home/anna/Documents/cinnabar\")\n",
    "import cinnabar\n",
    "\n",
    "print(\"adding code to the pythonpath...\")\n",
    "code = \"/home/anna/Documents/code/python\"\n",
    "if code not in sys.path:\n",
    "    sys.path.insert(1, code)\n",
    "import pipeline\n",
    "\n",
    "print(cinnabar.__file__)\n",
    "\n",
    "from pipeline import *\n",
    "from pipeline.utils import validate\n",
    "from pipeline.analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load in the data for the protein system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_folder = f\"/home/anna/Documents/benchmark\"\n",
    "protein = \"tyk2\"\n",
    "main_dir = f\"/backup/{protein}\"\n",
    "# main_dir = f\"/backup/manual_reruns/{protein}\"\n",
    "\n",
    "ana_obj_dict = {}\n",
    "\n",
    "# for the different networks\n",
    "for net in [\"lomap\", \"rbfenn\", \"combined\"]:\n",
    "    # choose location for the files\n",
    "    net_file = f\"{main_dir}/execution_model/network_{net}.dat\"\n",
    "    ana_file = f\"{main_dir}/execution_model/analysis_protocol.dat\"  # can also cycle through different analysis protocols\n",
    "    exp_file = f\"{bench_folder}/inputs/experimental/{protein}.yml\"\n",
    "\n",
    "    results_folder = f\"{main_dir}/outputs_extracted/results\"\n",
    "    output_folder = validate.folder_path(\n",
    "        f\"{main_dir}/analysis_paper_initial/{net}\", create=True\n",
    "    )\n",
    "\n",
    "    ana_obj = analysis_network(\n",
    "        results_folder,\n",
    "        exp_file=exp_file,\n",
    "        net_file=net_file,\n",
    "        output_folder=output_folder,\n",
    "        analysis_prot=ana_file,\n",
    "    )\n",
    "\n",
    "    # Add ligands folder for drawing\n",
    "\n",
    "    ana_obj.add_ligands_folder(f\"{bench_folder}/inputs/{protein}/ligands\")\n",
    "\n",
    "    ana_obj_dict[net] = ana_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ana_obj in ana_obj_dict.values():\n",
    "    for eng in ana_obj.engines:\n",
    "        for pert in ana_obj._perturbations_dict[eng]:\n",
    "            if pert == \"lig_jmc27~lig_jmc28\":\n",
    "                ana_obj.remove_perturbations(pert, name=eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse each object\n",
    "\n",
    "for ana_obj in ana_obj_dict.values():\n",
    "    ana_obj.remove_perturbations([\"lig_jmc27~lig_jmc28\"])\n",
    "\n",
    "    # compute results\n",
    "    ana_obj.compute_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reproducibility between perturbations\n",
    "\n",
    "this is for the combined networks\n",
    "\n",
    "check:\n",
    "vs experimental\n",
    "vs each other\n",
    "outliers for each engine\n",
    "most different perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj = ana_obj_dict[\"combined\"]\n",
    "\n",
    "# compared to each other\n",
    "mad_df, mad_df_err = ana_obj.calc_mad_engines(pert_val=\"pert\")\n",
    "print(mad_df)\n",
    "print(mad_df_err)\n",
    "\n",
    "# # compared to experimental\n",
    "mae_df, mae_df_err = ana_obj.calc_mae_engines(pert_val=\"pert\")\n",
    "print(mae_df)\n",
    "print(mae_df_err)\n",
    "\n",
    "# also saved in output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj.plot_scatter_ddG()\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    ana_obj.plot_scatter_ddG(engines=eng)\n",
    "    # ana_obj.plot_scatter_ddG(engines=eng, use_cinnabar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking results, convergence, spread of data between engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ana_obj in ana_obj_dict.values():\n",
    "    # can compute convergence for all\n",
    "    ana_obj.compute_convergence(main_dir=main_dir)\n",
    "    ana_obj.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms\n",
    "\n",
    "for ana_obj in ana_obj_dict.values():\n",
    "    ana_obj.plot_histogram_repeats()\n",
    "\n",
    "    ana_obj.plot_histogram_legs()\n",
    "\n",
    "    ana_obj.plot_histogram_sem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outliers for each engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj.plot_outliers(no_outliers=5, engines=ana_obj.engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in ana_obj.engines:\n",
    "    # get outliers above a certain threshold\n",
    "    perts = ana_obj.get_outliers(threshold=3, name=eng)\n",
    "    print(f\"{eng} : {perts}\")\n",
    "\n",
    "    # draw the perturbations\n",
    "    ana_obj.draw_perturbations(perts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perturbations that are the most different between the engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_engines_list_dict = {}\n",
    "\n",
    "for pert in ana_obj.perturbations:\n",
    "    all_engines_list_dict[pert] = []\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        all_engines_list_dict[pert].append(ana_obj.calc_pert_dict[eng][pert][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_largest_difference_pert(dictionary_of_lists, num_ranges):\n",
    "    ranges = {}\n",
    "\n",
    "    for key, sublist in dictionary_of_lists.items():\n",
    "        range = max(sublist) - min(sublist)\n",
    "        ranges[key] = range\n",
    "\n",
    "    sorted_ranges = sorted(ranges.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_ranges = sorted_ranges[:num_ranges]\n",
    "\n",
    "    return top_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ranges = find_top_largest_difference_pert(all_engines_list_dict, 5)\n",
    "print(top_ranges)\n",
    "perts = [a[0] for a in top_ranges]\n",
    "ana_obj.draw_perturbations(perts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj._plotting_object.scatter(\"pert\", values=perts, y_names=ana_obj.engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in ana_obj.engines:\n",
    "    print(eng)\n",
    "    for key in ana_obj.calc_pert_dict[eng].items():\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cycle closures\n",
    "\n",
    "for each network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in ana_obj_dict:\n",
    "    print(net)\n",
    "    ana_obj = ana_obj_dict[net]\n",
    "\n",
    "    ana_obj.compute_cycle_closures()\n",
    "\n",
    "    for eng in ana_obj.cycle_dict:\n",
    "        print(eng)\n",
    "        cycles = ana_obj.cycle_dict[eng]\n",
    "        print(f\"{eng} cycle vals is {cycles[1]}\")\n",
    "        print(f\"{eng} cycle mean is {cycles[2]}\")\n",
    "        print(f\"{eng} cycle deviation is {cycles[3]}\")\n",
    "\n",
    "        max_cycle_ind = max(cycles[1])\n",
    "        max_cycle = list(cycles[0].keys())[cycles[1].index(max_cycle_ind)]\n",
    "        print(max_cycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reproducibility between ligs - per ligand results\n",
    "\n",
    "this is for the individual networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for each network and calc mad / mae\n",
    "\n",
    "\n",
    "for net in ana_obj_dict:\n",
    "    print(net)\n",
    "    ana_obj = ana_obj_dict[net]\n",
    "\n",
    "    stats = ana_obj.calc_stats()\n",
    "\n",
    "    # plotting with r2, spearmans rank\n",
    "    for eng in ana_obj.engines:\n",
    "        # title = \"\"\n",
    "        # title += f\"{net}\"\n",
    "\n",
    "        # mue_exp = r2val = stats[\"val\"][\"experimental\"][eng][\"MUE\"]\n",
    "        # r2val = stats[\"val\"][\"experimental\"][eng][\"R2\"]\n",
    "        # rmseval = stats[\"val\"][\"experimental\"][eng][\"RMSE\"]\n",
    "        # spearman = stats[\"val\"][\"experimental\"][eng][\"rho\"]\n",
    "\n",
    "        # # titles\n",
    "        # title += f\"\\n MAE : {mue_exp[0]:.2f} +/- {mue_exp[1]:.2f} kcal/mol\"\n",
    "        # title += f\"\\n R2 : {r2val[0]:.2f} +/- {r2val[1]:.2f} kcal/mol\"\n",
    "        # title += f\"\\n RMSE : {rmseval[0]:.2f} +/- {rmseval[1]:.2f} kcal/mol\"\n",
    "        # title += f\"\\n rho : {spearman[0]:.2f} +/- {spearman[1]:.2f} kcal/mol\"\n",
    "\n",
    "        # kwargs = {\"title\": title}\n",
    "        # ana_obj.plot_scatter_dG(engine=eng, **kwargs)\n",
    "        ana_obj.plot_scatter_dG(engine=eng, use_cinnabar=True)\n",
    "\n",
    "    # compared to each other\n",
    "    mad_df, mad_df_err = ana_obj.calc_mad_engines(pert_val=\"val\")\n",
    "    print(mad_df)\n",
    "    print(mad_df_err)\n",
    "\n",
    "    # # compared to experimental\n",
    "    mae_df, mae_df_err = ana_obj.calc_mae_engines(pert_val=\"val\")\n",
    "    print(mae_df)\n",
    "    print(mae_df_err)\n",
    "\n",
    "    # also saved in output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### different network analysis methods\n",
    "\n",
    "all so far with cinnabar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared to fwf\n",
    "\n",
    "for net in ana_obj_dict:\n",
    "    print(net)\n",
    "    ana_obj = ana_obj_dict[net]\n",
    "\n",
    "    # first need to add the fwf path\n",
    "    ana_obj._add_fwf_path(\n",
    "        \"/home/anna/Documents/september_2022_workshops/freenrgworkflows/networkanalysis\"\n",
    "    )\n",
    "\n",
    "    title = \"\"\n",
    "    title += f\"{net}\"\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        # get the network analysis\n",
    "        fwf_dict = ana_obj._get_ana_fwf(engine=eng)\n",
    "        # for key in fwf_dict:\n",
    "        #     print(f\"{key} : {fwf_dict[key][0]}, {fwf_dict[key][1]}\")\n",
    "\n",
    "        # get fwf stats\n",
    "        fwf_stats = ana_obj._get_stats_fwf(engine=eng)\n",
    "\n",
    "        # compared to each other\n",
    "        mad_df, mad_df_err = ana_obj._get_mad_fwf(ana_obj.engines, ana_obj.engines)\n",
    "        print(mad_df)\n",
    "        print(mad_df_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared to mbarnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### consensus\n",
    "\n",
    "consensus scoring of the engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average of averages\n",
    "\n",
    "for net in ana_obj_dict:\n",
    "    ana_obj = ana_obj_dict[net]\n",
    "\n",
    "    consensus_pert_dict = {}\n",
    "\n",
    "    ana_obj.compute_consensus()\n",
    "\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consensus scoring, is it more robust\n",
    "\n",
    "for net in ana_obj_dict:\n",
    "    print(net)\n",
    "\n",
    "    ana_obj = ana_obj_dict[net]\n",
    "\n",
    "    for pv in [\"pert\", \"val\"]:\n",
    "        print(pv)\n",
    "        mae_df, mae_df_err = ana_obj.calc_mae_engines(pv, engines=\"consensus\")\n",
    "        print(mae_df)\n",
    "        print(mae_df_err)\n",
    "\n",
    "        stat_rank = ana_obj._stats_object.compute_rho(pv, y=\"consensus\")\n",
    "        print(stat_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparing different networks\n",
    "\n",
    "for the lomap and the rbfenn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_val_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the error for the different networks is lower\n",
    "\n",
    "error_dict = {}\n",
    "diff_to_exp_dict = {}\n",
    "\n",
    "for net in ana_obj_dict:\n",
    "    print(net)\n",
    "\n",
    "    ana_obj = ana_obj_dict[net]\n",
    "\n",
    "    error_dict[net] = {}\n",
    "    diff_to_exp_dict[net] = {}\n",
    "\n",
    "    for eng in ana_obj.engines:\n",
    "        error_val_dict = {}\n",
    "        diff_to_exp_val_dict = {}\n",
    "\n",
    "        for key in ana_obj.calc_pert_dict[eng]:\n",
    "            error_val_dict[key] = ana_obj.calc_pert_dict[eng][key][1]\n",
    "            diff_to_exp_val_dict[key] = abs(\n",
    "                ana_obj.calc_pert_dict[eng][key][0] - ana_obj.exper_pert_dict[key][0]\n",
    "            )\n",
    "\n",
    "        # test for normal distribution in the errors\n",
    "        # if less than 0.05, not normal\n",
    "        print(\n",
    "            \"error\",\n",
    "            scipy.stats.shapiro(\n",
    "                list(filter(lambda item: item is not None, error_val_dict.values()))\n",
    "            ),\n",
    "        )\n",
    "        print(\n",
    "            \"diff to exp\",\n",
    "            scipy.stats.shapiro(\n",
    "                list(\n",
    "                    filter(lambda item: item is not None, diff_to_exp_val_dict.values())\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        avg_error = np.mean(\n",
    "            list(filter(lambda item: item is not None, error_val_dict.values()))\n",
    "        )\n",
    "        avg_diff_exp = np.mean(\n",
    "            list(filter(lambda item: item is not None, diff_to_exp_val_dict.values()))\n",
    "        )\n",
    "\n",
    "        print(f\"{net}, {eng}, avg error is : {avg_error}\")\n",
    "        print(f\"{net}, {eng}, avg diff to exp is : {avg_diff_exp}\")\n",
    "\n",
    "        error_dict[net][eng] = error_val_dict\n",
    "        diff_to_exp_dict[net][eng] = diff_to_exp_val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mann whitney u, as not normally distributed\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    group1 = list(\n",
    "        filter(lambda item: item is not None, error_dict[\"lomap\"][eng].values())\n",
    "    )\n",
    "    group2 = list(\n",
    "        filter(lambda item: item is not None, error_dict[\"rbfenn\"][eng].values())\n",
    "    )\n",
    "\n",
    "    ustats, pvalue = scipy.stats.mannwhitneyu(group1, group2)\n",
    "\n",
    "    print(f\"{eng}: {ustats, pvalue}\")\n",
    "\n",
    "# if below 0.05 (if confidence interval) there is significant difference (reject null hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check difference to experimental sig diff between the two\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    group1 = list(\n",
    "        filter(lambda item: item is not None, diff_to_exp_dict[\"lomap\"][eng].values())\n",
    "    )\n",
    "    group2 = list(\n",
    "        filter(lambda item: item is not None, diff_to_exp_dict[\"rbfenn\"][eng].values())\n",
    "    )\n",
    "\n",
    "    ustats, pvalue = scipy.stats.mannwhitneyu(group1, group2)\n",
    "\n",
    "    print(f\"{eng}: {ustats, pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directionality\n",
    "\n",
    "data from featurising the perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj = ana_obj_dict[\"combined\"]\n",
    "\n",
    "grow_shrink_dict = {}\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    grow_shrink_dict[eng] = {}\n",
    "\n",
    "    error_dict = {\n",
    "        key: ana_obj.calc_pert_dict[eng][key][1] for key in ana_obj.calc_pert_dict[eng]\n",
    "    }\n",
    "    df = pd.read_csv(f\"{main_dir}/execution_model/grow_shrink_featurise.dat\")\n",
    "    df[f\"error_{eng}\"] = df[\"pert\"].map(error_dict)\n",
    "    df = df.dropna()\n",
    "\n",
    "    group1 = df.loc[df[\"grow/shrink\"] == \"grow\"][f\"error_{eng}\"]\n",
    "    group2 = df.loc[df[\"grow/shrink\"] == \"shrink\"][f\"error_{eng}\"]\n",
    "    ustats, pvalue = scipy.stats.mannwhitneyu(group1, group2)\n",
    "    print(f\"mann u for error {eng}: {ustats, pvalue}\")\n",
    "    print(\n",
    "        f\"mean for error {eng} grow: {np.mean(group1)}, and for shrink: {np.mean(group2)}\"\n",
    "    )\n",
    "\n",
    "    grow_shrink_dict[eng][\"grow_err\"] = group1\n",
    "    grow_shrink_dict[eng][\"shrink_err\"] = group2\n",
    "\n",
    "    # for diff to experimental\n",
    "    diff_dict = {\n",
    "        key: diff_to_exp_dict[\"combined\"][eng][key]\n",
    "        for key in ana_obj.calc_pert_dict[eng]\n",
    "    }\n",
    "    df[f\"diff_{eng}\"] = df[\"pert\"].map(diff_dict)\n",
    "    df = df.dropna()\n",
    "\n",
    "    group1 = df.loc[df[\"grow/shrink\"] == \"grow\"][f\"diff_{eng}\"]\n",
    "    group2 = df.loc[df[\"grow/shrink\"] == \"shrink\"][f\"diff_{eng}\"]\n",
    "    ustats, pvalue = scipy.stats.mannwhitneyu(group1, group2)\n",
    "    print(f\"mann u for diff to exp {eng}: {ustats, pvalue}\")\n",
    "    print(\n",
    "        f\"mean for diff to exp {eng} grow: {np.mean(group1)}, and for shrink: {np.mean(group2)}\"\n",
    "    )\n",
    "\n",
    "    grow_shrink_dict[eng][\"grow_diff\"] = group1\n",
    "    grow_shrink_dict[eng][\"shrink_diff\"] = group2\n",
    "\n",
    "# if below 0.05 (if confidence interval) there is significant difference (reject null hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different between engines significant?\n",
    "\n",
    "res_dict = {}\n",
    "\n",
    "for size in [\"grow_err\", \"shrink_err\", \"grow_diff\", \"shrink_diff\"]:\n",
    "    res_dict[size] = {}\n",
    "\n",
    "    for eng in ana_obj_dict[\"combined\"].engines:\n",
    "        res_dict[size][eng] = {}\n",
    "\n",
    "    for combo in it.product(grow_shrink_dict.keys(), grow_shrink_dict.keys()):\n",
    "        eng1 = combo[0]\n",
    "        eng2 = combo[1]\n",
    "\n",
    "        if eng1 == eng2:\n",
    "            continue\n",
    "\n",
    "        group1 = grow_shrink_dict[eng1][size]\n",
    "        group2 = grow_shrink_dict[eng2][size]\n",
    "\n",
    "        ustats, pvalue = scipy.stats.mannwhitneyu(group1, group2)\n",
    "        print(f\"{eng1, eng2}, {size}: {ustats, pvalue}\")\n",
    "        print(f\"mean for {eng1}: {np.mean(group1)}, and for {eng2}: {np.mean(group2)}\")\n",
    "\n",
    "        res_dict[size][eng1][eng2] = pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(res_dict[\"grow_err\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size of perturbation and variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_obj = ana_obj_dict[\"combined\"]\n",
    "\n",
    "file = f\"{bench_folder}/extracted/{protein}/perturbing_overlap.dat\"\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df = df[df[\"engine\"] == eng]\n",
    "\n",
    "    error_dict = {\n",
    "        key: ana_obj.calc_pert_dict[eng][key][1] for key in ana_obj.calc_pert_dict[eng]\n",
    "    }\n",
    "    df[f\"error\"] = df[\"perturbation\"].map(error_dict)\n",
    "    # df = df.dropna()\n",
    "    df = df[df[\"error\"].notna()]\n",
    "    df = df[df[\"perturbing_atoms\"].notna()]\n",
    "\n",
    "    stats = pipeline.analysis.stats_engines.compute_stats(\n",
    "        [x for x in df[\"perturbing_atoms\"]], [x for x in df[\"error\"]], statistic=\"R2\"\n",
    "    )\n",
    "    df.plot.scatter(\n",
    "        \"perturbing_atoms\",\n",
    "        \"error\",\n",
    "        c=\"diff_to_exp\",\n",
    "        colormap=\"viridis\",\n",
    "        title=f\"{eng}\\n{stats}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### different analysis methods\n",
    "\n",
    "the different analysis methods (MBAR/TI, % of run used, stats ineff, autoeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add other analyses as other results\n",
    "\n",
    "ana_obj = ana_obj_dict[\"combined\"]\n",
    "\n",
    "for eng in ana_obj.engines:\n",
    "    other_results = glob.glob(\n",
    "        f\"{results_folder}/freenrg_*_{eng}_TI_alchemlyb_None_eqfalse_statsfalse_truncate0end.csv\"\n",
    "    )\n",
    "    bound_results = glob.glob(\n",
    "        f\"{results_folder}/bound_*_{eng}_TI_alchemlyb_None_eqfalse_statsfalse_truncate0end.csv\"\n",
    "    )\n",
    "    free_results = glob.glob(\n",
    "        f\"{results_folder}/free_*_{eng}_TI_alchemlyb_None_eqfalse_statsfalse_truncate0end.csv\"\n",
    "    )\n",
    "    ana_obj.compute_other_results(\n",
    "        other_results,\n",
    "        name=f\"{eng}_TI\",\n",
    "        bound_files=bound_results,\n",
    "        free_files=free_results,\n",
    "    )\n",
    "\n",
    "# for eng in ana_obj.engines:\n",
    "\n",
    "#     other_results = glob.glob(\n",
    "#         f\"{results_folder}/freenrg_*_{eng}_MBAR_alchemlyb_None_eqtrue_statstrue_truncate0end.csv\"\n",
    "#     )\n",
    "#     bound_results = glob.glob(\n",
    "#         f\"{results_folder}/bound_*_{eng}_MBAR_alchemlyb_None_eqtrue_statstrue_truncate0end.csv\"\n",
    "#     )\n",
    "#     free_results = glob.glob(\n",
    "#         f\"{results_folder}/free_*_{eng}_MBAR_alchemlyb_None_eqtrue_statstrue_truncate0end.csv\"\n",
    "#     )\n",
    "#     ana_obj.compute_other_results(\n",
    "#         other_results, name=f\"{eng}_MBAR_stats_eq\", bound_files=bound_results, free_files=free_results\n",
    "#     )\n",
    "\n",
    "# for eng in ana_obj.engines:\n",
    "\n",
    "#     other_results = glob.glob(\n",
    "#         f\"{results_folder}/freenrg_*_{eng}_MBAR_alchemlyb_None_eqfalse_statstrue_truncate0end.csv\"\n",
    "#     )\n",
    "#     bound_results = glob.glob(\n",
    "#         f\"{results_folder}/bound_*_{eng}_MBAR_alchemlyb_None_eqfalse_statstrue_truncate0end.csv\"\n",
    "#     )\n",
    "#     free_results = glob.glob(\n",
    "#         f\"{results_folder}/free_*_{eng}_MBAR_alchemlyb_None_eqfalse_statstrue_truncate0end.csv\"\n",
    "#     )\n",
    "#     ana_obj.compute_other_results(\n",
    "#         other_results, name=f\"{eng}_MBAR_stats\", bound_files=bound_results, free_files=free_results\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in ana_obj.engines:\n",
    "    stat_r2 = ana_obj._stats_object.compute_r2(\"pert\", f\"{eng}_TI\", f\"{eng}\")\n",
    "    stat_r2_string = f\"{stat_r2[0]:.2f} +/- {stat_r2[1]:.2f}\"\n",
    "    # ana_obj.plot_eng_vs_eng(engine_a=f\"{eng}_TI\", engine_b=f\"{eng}\", **{\"title\":f\"{eng} vs {eng}_TI\\n{stat_r2_string}\"})\n",
    "\n",
    "    ana_obj._plotting_object.scatter(\n",
    "        pert_val=\"pert\",\n",
    "        y_names=f\"{eng}_TI\",\n",
    "        x_name=f\"{eng}\",\n",
    "        outliers=True,\n",
    "        no_outliers=3,\n",
    "        **{\"title\": f\"{eng} vs {eng}_TI\\n{stat_r2_string}\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
