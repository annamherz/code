{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:teal\">RBFE Network - Analysis</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anna/anaconda3/envs/biosimspace-dev/lib/python3.9/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/anna/anaconda3/envs/biosimspace-dev/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/anna/anaconda3/envs/biosimspace-dev/lib/python3.9/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/anna/anaconda3/envs/biosimspace-dev/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================\n",
      "Sending anonymous Sire usage statistics to http://siremol.org.\n",
      "For more information, see http://siremol.org/analytics\n",
      "To disable, set the environment variable 'SIRE_DONT_PHONEHOME' to 1\n",
      "To see the information sent, set the environment variable \n",
      "SIRE_VERBOSE_PHONEHOME equal to 1. To silence this message, set\n",
      "the environment variable SIRE_SILENT_PHONEHOME to 1.\n",
      "==============================================================\n",
      "\n",
      "/home/anna/anaconda3/envs/biosimspace-dev/lib/python3.9/site-packages/cinnabar/__init__.py\n",
      "An installation of AMBER is required: https://ambermd.org/. Please install AMBER and set the AMBERHOME environment variable\n",
      "A GROMACS installation is required: https://www.gromacs.org/. Please install GROMACS and include it in your PATH\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import BioSimSpace as BSS\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import yaml\n",
    "from scipy.stats import sem as sem\n",
    "from scipy.stats import bootstrap\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import pickle\n",
    "import tempfile\n",
    "import itertools\n",
    "\n",
    "# import from path for freenrgworkflows.\n",
    "import sys\n",
    "sys.path.insert(1, '/home/anna/Documents/september_2022_workshops/freenrgworkflows/networkanalysis/') # FIXME this will need to be adjusted in the future\n",
    "import networkanalysis\n",
    "import experiments\n",
    "import stats\n",
    "\n",
    "# try w cinnabar\n",
    "sys.path.insert(1, '/home/anna/Documents/cinnabar')\n",
    "import cinnabar\n",
    "from cinnabar import wrangle,plotting\n",
    "print(cinnabar.__file__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from rdkit import Chem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders\n",
    "protein = \"tyk2\"\n",
    "file_ext = \"MBAR_alchemlyb_benchmark\" # for results files\n",
    "\n",
    "# define all the folder locations\n",
    "bench_folder = f\"/home/anna/Documents/benchmark\"\n",
    "main_folder = f\"{bench_folder}/{protein}_benchmark\"\n",
    "out_folder = f\"{main_folder}/outputs\"\n",
    "res_folder = f\"{main_folder}/outputs/results\"\n",
    "temp_folder = f\"{main_folder}/outputs/results/temp\"\n",
    "exp_folder = f\"{bench_folder}/inputs/experimental\"\n",
    "\n",
    "# make folders that may not exist\n",
    "folder_list = [res_folder, temp_folder]\n",
    "for fold in folder_list:\n",
    "    if not os.path.isdir(fold):\n",
    "        os.mkdir(fold)\n",
    "        print(f\"Made dir {fold}\")\n",
    "\n",
    "# files\n",
    "net_file = f\"{main_folder}/execution_model/network_lomap.dat\"\n",
    "exp_file = f\"{exp_folder}/{protein}.yml\"\n",
    "exp_file_dat = f\"{exp_folder}/exp_data_{protein}.dat\"\n",
    "\n",
    "# OUTPUT\n",
    "file_ext_out = \"MBAR_alchemlyb_lomap\" # for how files will be written\n",
    "\n",
    "# files that will get written\n",
    "comp_pert_file_name = f\"computed_perturbations_average_{file_ext_out}\"\n",
    "cinnabar_file = f\"cinnabar_format_{file_ext_out}\"\n",
    "# TODO add file names for saving graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO put all functions into thing so can just call here, also do this for ligprep and fepprep functions\n",
    "\n",
    "# functions\n",
    "# TODO clean up and make sure have description at start\n",
    "\n",
    "def convert_yml_into_freenrgworkflows(exp_file, exp_file_dat):\n",
    "    # get the experimental data into a useable format (from yml to csv)\n",
    "    # for freenergworkflows, want to save as lig, Ki\n",
    "    # experimental values (e.g. ic50/ki) for all ligands in our set.\n",
    "    with open(exp_file, \"r\") as file:\n",
    "        data = yaml.safe_load(file) # loads as dictionary\n",
    "\n",
    "    with open(exp_file_dat, \"w\") as file:\n",
    "        writer = csv.writer(file, delimiter=\",\")\n",
    "        writer.writerow([\"ligand\",\"value\",\"error\"])\n",
    "\n",
    "        # the data needs to be IC50, uM\n",
    "        # am assuming that ki and IC50 are the same\n",
    "        \n",
    "        for key in data.keys(): # write for each ligand that was in yaml file\n",
    "            if data[key]['measurement']['unit'] == 'uM':\n",
    "                writer.writerow([key, data[key]['measurement']['value'], data[key]['measurement']['error']])\n",
    "            elif data[key]['measurement']['unit'] == 'nM':\n",
    "                writer.writerow([key, \"{:.4f}\".format(data[key]['measurement']['value']/1000), data[key]['measurement']['error']/1000])\n",
    "\n",
    "\n",
    "\n",
    "def get_info_network(engine=None, results_files=None, net_file=None, output_folder=None, extra_options=None):\n",
    "    # get info from a network file for engine\n",
    "    # For the network that we are considering,\n",
    "    # we want to get results files with these perturbations from the overall file that contains the large network results (if this is the case).\n",
    "    # This is just good to have a consistent format of results to analyse.\n",
    "    if not engine:\n",
    "        raise ValueError(\"must specify an engine\") # TODO make so can be BSS engines or all engines allowed\n",
    "    # TODO if not out_folder is a file path, raise issue\n",
    "    # if not engine:\n",
    "    #     raise ValueError(\"must specify an engine\")    \n",
    "    # TODO if not temp folder make\n",
    "\n",
    "    # get all the indivisual results file for that engine\n",
    "    # TODO if results file is empty, raise issue\n",
    "    # TODO print how many results files\n",
    "    # TODO extra options if want to change file name etc, also put if only want a specific engine here?\n",
    "    # otherwise will find all engines in network file and use this\n",
    "\n",
    "    # We also want to create a list of the perturbations in our network.\n",
    "    # create a list of the perturbations\n",
    "    perturbations = []\n",
    "\n",
    "    # create a list of ligands\n",
    "    ligands = []\n",
    "\n",
    "    # use the network file to find the ligands and perturbations\n",
    "    for line in open(f\"{net_file}\", \"r\"):\n",
    "        if line.split()[-1] == engine:\n",
    "            lig_0 = line.split()[0]\n",
    "            lig_1 = line.split()[1]\n",
    "            pert = f\"{lig_0}~{lig_1}\"\n",
    "            perturbations.append(pert)\n",
    "            if lig_0 not in ligands:\n",
    "                ligands.append(lig_0)\n",
    "            elif lig_1 not in ligands:\n",
    "                ligands.append(lig_1)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    mod_results_files = []\n",
    "\n",
    "    for file in results_files:\n",
    "        new_file_name = f\"{output_folder}/results_{results_files.index(file)}_{engine}.csv\"\n",
    "        with open(new_file_name, \"w\") as result_file:\n",
    "\n",
    "            writer = csv.writer(result_file, delimiter=\",\")\n",
    "            writer.writerow([\"lig_1\",\"lig_2\",\"freenrg\",\"error\",\"engine\"])\n",
    "\n",
    "            for row, index in pd.read_csv(file).iterrows():\n",
    "                pert = f\"{index['lig_1']}~{index['lig_2']}\"\n",
    "                if pert in perturbations:\n",
    "                    writer.writerow([index['lig_1'], index['lig_2'], index['freenrg'], index['error'], index['engine']])    \n",
    "\n",
    "            mod_results_files.append(new_file_name)\n",
    "\n",
    "    return perturbations, ligands, mod_results_files\n",
    "\n",
    "\n",
    "def gen_graph(ligands=None, perturbations=None, file_dir=None):\n",
    "\n",
    "    # TODO error check if not lists, etc\n",
    "    # Generate the graph.\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    # Loop over the nligands and add as nodes to the graph.\n",
    "    for lig in ligands:\n",
    "        graph.add_node(lig, label=lig, labelloc=\"t\")\n",
    "\n",
    "    # Loop over the edges in the dictionary and add to the graph.\n",
    "    for edge in perturbations:\n",
    "        lig_0 = edge.split(\"~\")[0]\n",
    "        lig_1 = edge.split(\"~\")[1]\n",
    "        graph.add_edge(lig_0, lig_1)\n",
    "\n",
    "    # Plot the networkX graph.\n",
    "    pos = nx.kamada_kawai_layout(graph)\n",
    "    plt.figure(figsize=(8,8), dpi=150)\n",
    "    nx.draw(\n",
    "        graph, pos, edge_color='black', width=1, linewidths=1,\n",
    "        node_size=2100, node_color='darkblue', font_size = 9.5,\n",
    "        labels={node: node for node in graph.nodes()},\n",
    "        font_color = \"white\")\n",
    "\n",
    "    plt.savefig(f\"{file_dir}/analysis_network.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# make dictionary of values of results\n",
    "def make_dict_comp_results(results_files=None, perturbations=None, file_name=None, engine=None):\n",
    "\n",
    "    # TODO some way to get engine from results files?\n",
    "    # make a dictionary with the results of the files\n",
    "    comp_dict_list = {}\n",
    "    comp_err_dict_list = {}\n",
    "\n",
    "    # append for results file\n",
    "    for res_file in results_files:\n",
    "        res_df = pd.read_csv(res_file)\n",
    "        for index,row in res_df.iterrows():\n",
    "            lig_0 = row[0]\n",
    "            lig_1 = row[1]\n",
    "            pert = f\"{lig_0}~{lig_1}\"\n",
    "            if not isinstance(row[2], float):\n",
    "                ddG = BSS.Types.Energy(float(row[2].split()[0]),row[2].split()[-1])\n",
    "            else:\n",
    "                ddG = row[2]\n",
    "            if not isinstance(row[3], float):\n",
    "                ddG_err = BSS.Types.Energy(float(row[3].split()[0]),row[3].split()[-1])\n",
    "            else:\n",
    "                ddG_err = row[3]\n",
    "                \n",
    "            if pert in comp_dict_list:\n",
    "                # Key exist in dict, check if is a list\n",
    "                if not isinstance(comp_dict_list[pert], list):\n",
    "                    # If type is not list then make it list\n",
    "                    comp_dict_list[pert] = [comp_dict_list[pert]]\n",
    "                if not isinstance(comp_err_dict_list[pert], list):\n",
    "                    # If type is not list then make it list\n",
    "                    comp_err_dict_list[pert] = [comp_err_dict_list[pert]]\n",
    "                # Append the value in list\n",
    "                comp_dict_list[pert].append(ddG)\n",
    "                comp_err_dict_list[pert].append(ddG_err)\n",
    "            else:\n",
    "                # As key is not in dict,\n",
    "                # so, add key-value pair\n",
    "                comp_dict_list[pert] = ddG\n",
    "                comp_err_dict_list[pert] = ddG_err\n",
    "\n",
    "    # now calculate all the avg and SEM for the network perturbations\n",
    "    # put these into a dictionary\n",
    "    comp_diff_dict = {}\n",
    "\n",
    "    # TODO if none, don't write to csv file\n",
    "    # write these to a csv file\n",
    "    with open(f\"{file_name}.csv\", \"w\") as comp_pert_file:\n",
    "        writer = csv.writer(comp_pert_file, delimiter=\",\")\n",
    "        writer.writerow([\"lig_1\",\"lig_2\",\"freenrg\",\"error\",\"engine\"])\n",
    "        for pert in perturbations:\n",
    "            lig_0 = pert.split(\"~\")[0]\n",
    "            lig_1 = pert.split(\"~\")[1]\n",
    "            \n",
    "            # check if the perturbations calculated are also those in the network file and if any are missing\n",
    "            try:\n",
    "                # find the values in the dictionary\n",
    "                ddGs = comp_dict_list[pert]\n",
    "                ddGs_error = comp_err_dict_list[pert]\n",
    "                # calculate the average and the error\n",
    "                comp_ddG = np.average(ddGs)\n",
    "                # comp_ddG = np.average([ddG.value() for ddG in ddGs])\n",
    "                if len(ddGs) == 1:\n",
    "                    comp_err = ddGs_error.value()\n",
    "                else:\n",
    "                    comp_err = sem(ddGs)\n",
    "                    # comp_err = sem([ddG.value() for ddG in ddGs])\n",
    "        \n",
    "            # if unable to calculate one of the perturbations, this is a None value.\n",
    "            except:\n",
    "                comp_ddG = None\n",
    "                comp_err = None\n",
    "            \n",
    "            # TODO some way to incl units\n",
    "\n",
    "            #update the dictionary for plotting later\n",
    "            comp_diff_dict.update({pert:(comp_ddG, comp_err)})\n",
    "\n",
    "            writer.writerow([lig_0, lig_1, comp_ddG, comp_err, engine])\n",
    "    \n",
    "    return comp_diff_dict\n",
    "\n",
    "def freenrgworkflows_into_dict(experimental_DDGs, ligands, perturbations):\n",
    "    # create a dictionary for the experimental values\n",
    "    exper_val_dict = {}\n",
    "\n",
    "    # convert the list of dicitonaries from freenrgworkflows into a single dictionary\n",
    "    for lig_dict in experimental_DDGs:\n",
    "        lig_name = list(lig_dict.keys())[0]\n",
    "        exper = lig_dict[lig_name]\n",
    "        exper_err = lig_dict[\"error\"]\n",
    "        exper_val_dict.update({lig_name:(exper, exper_err)})\n",
    "\n",
    "    # add any ligands that are in the ligands file but dont have experimental values for\n",
    "    for lig_name in ligands:\n",
    "        if lig_name in exper_val_dict:\n",
    "            pass\n",
    "        else:\n",
    "            exper_val_dict.update({lig_name:(None, None)})\n",
    "\n",
    "    # now that we have our dictionary, \n",
    "    # we can also create a dictionary with all the experimental values for the perturbations\n",
    "    exper_diff_dict = {}\n",
    "\n",
    "    # calculate the experimental RBFEs\n",
    "    # write these to a csv file\n",
    "    with open(\"experimental_perturbations.csv\", \"w\") as exp_pert_file:\n",
    "        writer = csv.writer(exp_pert_file, delimiter=\",\")\n",
    "        writer.writerow([\"lig_1\",\"lig_2\",\"freenrg\",\"error\",\"engine\"])\n",
    "\n",
    "        for pert in perturbations:\n",
    "            lig_0 = pert.split(\"~\")[0]\n",
    "            lig_1 = pert.split(\"~\")[1]\n",
    "            # exclude from calculating if one of the ligands is not available\n",
    "            if exper_val_dict[lig_0][0] is None or exper_val_dict[lig_1][0] is None:\n",
    "                exper_ddG =None\n",
    "                exper_err = None\n",
    "                exper_diff_dict.update({pert:(None, None)})\n",
    "            # if experimental data is available, calculate experimental perturbation and propagate\n",
    "            else:\n",
    "                exper_ddG = exper_val_dict[lig_1][0] - exper_val_dict[lig_0][0]\n",
    "                exper_err = math.sqrt(math.pow(exper_val_dict[lig_0][1], 2) + math.pow(exper_val_dict[lig_1][1], 2))\n",
    "                exper_diff_dict.update({pert:(exper_ddG, exper_err)})\n",
    "\n",
    "            writer.writerow([lig_0, lig_1, exper_ddG, exper_err, \"experimental\"])\n",
    "\n",
    "    return exper_diff_dict, exper_val_dict\n",
    "\n",
    "\n",
    "def calc_mae(values_dict=None, perts_ligs = None):\n",
    "    # calc mae for a provided dictionary in the format wanted\n",
    "\n",
    "    values_dict_list = []\n",
    "    for key in values_dict.keys():\n",
    "        values_dict_list.append(key)\n",
    "\n",
    "    mae_pert_df = pd.DataFrame(columns=values_dict_list,index=values_dict_list)\n",
    "    mae_pert_df_err = pd.DataFrame(columns=values_dict_list,index=values_dict_list)\n",
    "\n",
    "    # iterate over all possible combinations\n",
    "    for combo in itertools.product(values_dict_list,values_dict_list):\n",
    "        eng1 = combo[0]\n",
    "        eng2 = combo[1]\n",
    "\n",
    "        eng1_vals = []\n",
    "        eng2_vals = []\n",
    "\n",
    "        # first create df of values\n",
    "        if perts_ligs == \"perts\":\n",
    "            for pert in values_dict[eng1][\"pert_results\"]:\n",
    "                if pert in values_dict[eng2][\"pert_results\"]:\n",
    "                    if values_dict[eng1][\"pert_results\"][pert][0] != None:\n",
    "                        if values_dict[eng2][\"pert_results\"][pert][0] != None:\n",
    "                            eng1_vals.append(values_dict[eng1][\"pert_results\"][pert][0])\n",
    "                            eng2_vals.append(values_dict[eng2][\"pert_results\"][pert][0])\n",
    "        elif perts_ligs == \"ligs\":\n",
    "            for pert in values_dict[eng1][\"val_results\"]:\n",
    "                if pert in values_dict[eng2][\"val_results\"]:\n",
    "                    if values_dict[eng1][\"val_results\"][pert][0] != None:\n",
    "                        if values_dict[eng2][\"val_results\"][pert][0] != None:\n",
    "                            eng1_vals.append(values_dict[eng1][\"val_results\"][pert][0])\n",
    "                            eng2_vals.append(values_dict[eng2][\"val_results\"][pert][0])\n",
    "        else:\n",
    "            raise ValueError(\"'perts_ligs' must be either 'perts' or 'ligs'!\")\n",
    "\n",
    "\n",
    "        if len(eng1_vals) == len(eng2_vals):\n",
    "            mean_absolute_error = mae(eng1_vals,eng2_vals)  \n",
    "            data_for_df = {\"eng1\":eng1_vals,\"eng2\":eng2_vals}\n",
    "            data_df= pd.DataFrame(data_for_df)\n",
    "        else:\n",
    "            print(\"cant calc\")\n",
    "\n",
    "        boots = []\n",
    "        n_boots = 10000\n",
    "\n",
    "        for n in range(n_boots):\n",
    "            sample_df = data_df.sample(n=len(eng1_vals), replace=True)\n",
    "            mae_sample = (abs(sample_df['eng1'] - sample_df['eng2']).sum())/len(eng1_vals)\n",
    "            boots.append(mae_sample)\n",
    "            mae_err = (np.std(boots))\n",
    "\n",
    "        mae_pert_df.loc[eng1,eng2]=mean_absolute_error\n",
    "        mae_pert_df_err.loc[eng1,eng2]=mae_err\n",
    "\n",
    "    mae_pert_df.to_csv(f\"{res_folder}/mae_pert_{file_ext_out}.csv\", sep=\" \")\n",
    "    mae_pert_df_err.to_csv(f\"{res_folder}/mae_pert_err_{file_ext_out}.csv\", sep=\" \")\n",
    "\n",
    "    return mae_pert_df, mae_pert_df_err\n",
    "\n",
    "\n",
    "def convert_cinnabar_file(results_files, exper_val_dict, output_file):\n",
    "    # files is a list of files\n",
    "    # output file\n",
    "\n",
    "    # write to a csv file\n",
    "    with open(f\"{output_file}.csv\", \"w\") as cinnabar_data_file:\n",
    "        writer = csv.writer(cinnabar_data_file, delimiter=\",\")\n",
    "\n",
    "        # first, write the experimental data\n",
    "        writer.writerow([\"# Experimental block\"])\n",
    "        writer.writerow([\"# Ligand\",\"expt_DDG\",\"expt_dDDG\"])\n",
    "\n",
    "\n",
    "        # TODO write function to convert experimental values instead of freenergworkflows (take from other ana)\n",
    "        for lig in exper_val_dict.keys():\n",
    "            writer.writerow([lig,f\"{exper_val_dict[lig][0]}\",f\"{exper_val_dict[lig][1]}\"])\n",
    "\n",
    "\n",
    "        # second write the perturbation data\n",
    "        writer.writerow([\" \"])\n",
    "        writer.writerow([\"# Calculated block\"])\n",
    "        writer.writerow([\"# Ligand1\",\"Ligand2\",\"calc_DDG\",\"calc_dDDG(MBAR)\", \"calc_dDDG(additional)\"])\n",
    "\n",
    "        for file in results_files:\n",
    "            with open(file, \"r\") as res_file:\n",
    "                for line in res_file:\n",
    "                    if \"freenrg\" in line: # avoid the header\n",
    "                        pass\n",
    "                    else:                           # write each perturbation and repeat to the file\n",
    "                        lig_0 = line.split(\",\")[0]\n",
    "                        lig_1 = line.split(\",\")[1]\n",
    "                        comp_ddG = line.split(\",\")[2]\n",
    "                        comp_err = line.split(\",\")[3]\n",
    "            \n",
    "                        writer.writerow([lig_0, lig_1, comp_ddG, comp_err, \"0.0\"])\n",
    "\n",
    "def gen_graph(ligands=None, perturbations=None, file_dir=None):\n",
    "\n",
    "    # TODO error check if not lists, etc\n",
    "    # Generate the graph.\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    # Loop over the nligands and add as nodes to the graph.\n",
    "    for lig in ligands:\n",
    "        graph.add_node(lig, label=lig, labelloc=\"t\")\n",
    "\n",
    "    # Loop over the edges in the dictionary and add to the graph.\n",
    "    for edge in perturbations:\n",
    "        lig_0 = edge.split(\"~\")[0]\n",
    "        lig_1 = edge.split(\"~\")[1]\n",
    "        graph.add_edge(lig_0, lig_1)\n",
    "\n",
    "    # Plot the networkX graph.\n",
    "    pos = nx.kamada_kawai_layout(graph)\n",
    "    plt.figure(figsize=(8,8), dpi=150)\n",
    "    nx.draw(\n",
    "        graph, pos, edge_color='black', width=1, linewidths=1,\n",
    "        node_size=2100, node_color='darkblue', font_size = 9.5,\n",
    "        labels={node: node for node in graph.nodes()},\n",
    "        font_color = \"white\")\n",
    "\n",
    "    plt.savefig(f\"{file_dir}/analysis_network.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    return graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will define the engine here for ease\n",
    "engines = [\"SOMD\",\"AMBER\",\"GROMACS\"]\n",
    "\n",
    "# make a dict of dicts - main dict is engines\n",
    "values_dict = {}\n",
    "\n",
    "values_dict_list = []\n",
    "for eng in engines:\n",
    "    values_dict_list.append(eng)\n",
    "values_dict_list.append(\"experimental\")\n",
    "\n",
    "for eng in values_dict_list: \n",
    "    values_dict[eng] = {} # dicts inside are :\n",
    "    values_dict[eng][\"results_files\"] = None\n",
    "    values_dict[eng][\"perts\"] = None\n",
    "    values_dict[eng][\"ligs\"] = None\n",
    "    values_dict[eng][\"pert_results\"] = None\n",
    "    values_dict[eng][\"val_results\"] = None\n",
    "    values_dict[eng][\"freenrg_df_pert\"] = None\n",
    "    values_dict[eng][\"freenrg_df_val\"] = None\n",
    "    values_dict[eng][\"freenrgworkflows_ouput\"] = None\n",
    "    values_dict[eng][\"cycle_closures\"] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good idea to check the network considering etc.\n",
    "# can use the perts obtained from the get_info_network, and then plot this.\n",
    "# can collate all perts and ligands for all engines as well\n",
    "\n",
    "all_perturbations = []\n",
    "all_ligands = []\n",
    "\n",
    "# run for all engines with selected network and populate the dictionary for plotting\n",
    "for eng in engines:\n",
    "    results_all_files = glob.glob(f\"{out_folder}/repeat_*_{eng}_{file_ext}.csv\")\n",
    "\n",
    "    # first get network info for each engine\n",
    "    values = get_info_network(eng, results_files=results_all_files,\n",
    "                                net_file=net_file,\n",
    "                                output_folder=temp_folder)\n",
    "    values_dict[eng][\"results_files\"] = values[2]\n",
    "    values_dict[eng][\"perts\"] = values[0]\n",
    "    values_dict[eng][\"ligs\"] = values[1]\n",
    "\n",
    "    for pert in values[0]:\n",
    "        if pert not in all_perturbations:\n",
    "            all_perturbations.append(pert)\n",
    "    for lig in values[1]:\n",
    "        if lig not in all_ligands:\n",
    "            all_ligands.append(lig)\n",
    "\n",
    "    # make a dict of the computed results\n",
    "    comp_dict = make_dict_comp_results(results_files=values_dict[eng][\"results_files\"], \n",
    "                                        perturbations=values_dict[eng][\"perts\"],\n",
    "                                        file_name=f\"{res_folder}/{comp_pert_file_name}_{eng}\",\n",
    "                                        engine=eng)\n",
    "    values_dict[eng][\"pert_results\"] = comp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can generate graph to visualise\n",
    "eng=\"SOMD\" # should be the same for each engine\n",
    "gen_graph(values_dict[eng][\"ligs\"],values_dict[eng][\"perts\"],out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also want to save exp results for plotting and comparison\n",
    "\n",
    "# first need to convert the yml file into one useable by freenergworkflows\n",
    "convert_yml_into_freenrgworkflows(exp_file, exp_file_dat)\n",
    "# TODO diff exp conversion that doesnt rely on freenrgworkflows\n",
    "# using freenergworkflows to convert\n",
    "experiments = experiments.ExperimentalData()\n",
    "experiments.compute_affinities(exp_file_dat, data_type=\"IC50\", comments=\"#\", delimiter=\",\")\n",
    "experimental_DDGs = experiments.freeEnergiesInKcal\n",
    "\n",
    "exp_pert_dict,exp_lig_dict = freenrgworkflows_into_dict(experimental_DDGs, all_ligands, all_perturbations)\n",
    "\n",
    "values_dict[\"experimental\"][\"perts\"] = all_perturbations\n",
    "values_dict[\"experimental\"][\"ligs\"] = all_ligands\n",
    "values_dict[\"experimental\"][\"pert_results\"] = exp_pert_dict\n",
    "values_dict[\"experimental\"][\"val_results\"] = exp_lig_dict\n",
    "values_dict[\"experimental\"][\"freenrgworkflows_ouput\"] = experimental_DDGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_DDGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:teal\">1.3 Plotting</span>\n",
    "<a id=\"plot\"></a>\n",
    "\n",
    "Now we have our computational and experimental in dicitonary format, we can turn this into a pandas dataframe. For plotting it is typically easier to work with the pandas library, which is why this next piece of code will reshape it to this.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# construct dict with experimental freenrg and error and computed\n",
    "for eng in engines:\n",
    "    freenrg_pert_dict = {}\n",
    "    for pert in values_dict[eng][\"perts\"]:\n",
    "        exp_ddG = values_dict[\"experimental\"][\"pert_results\"][pert][0]\n",
    "        exp_err = values_dict[\"experimental\"][\"pert_results\"][pert][1]\n",
    "        comp_ddG = values_dict[eng][\"pert_results\"][pert][0]\n",
    "        comp_err = values_dict[eng][\"pert_results\"][pert][1]\n",
    "        freenrg_pert_dict[pert] = [exp_ddG, exp_err, comp_ddG, comp_err]\n",
    "    freenrg_df_pert = pd.DataFrame(freenrg_pert_dict, index=[\"freenrg_exp\", \"err_exp\", \"freenrg_fep\", \"err_fep\"]).transpose()\n",
    "    values_dict[eng][\"freenrg_df_pert\"] = freenrg_df_pert\n",
    "\n",
    "    # save our results to a file that can be opened in e.g. Excel.\n",
    "    freenrg_df_pert.to_csv(f\"{res_folder}/fep_diff_results_table_{file_ext_out}_{eng}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if want to find a specific list of values for plotting, can do w something like this:\n",
    "# none_vals = freenrg_df_pert.index[freenrg_df_pert[\"freenrg_exp\"]>1].tolist()\n",
    "# and do this to get what perturbations it is, and then get the x,y values for these perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot individual engine scatter\n",
    "# engine = \"AMBER\"\n",
    "\n",
    "for engine in engines:\n",
    "    print(engine)\n",
    "    # check the outputed data frame - if want to get rid of the NaN values entirely can do\n",
    "    freenrg_df_pert_plotting_scatter = values_dict[engine][\"freenrg_df_pert\"].dropna()\n",
    "\n",
    "    # plot a scatter plot\n",
    "    plt.rc('font', size=12)\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "    # get these based on which column the data is in.\n",
    "    x = freenrg_df_pert_plotting_scatter[\"freenrg_exp\"]\n",
    "    y = freenrg_df_pert_plotting_scatter[\"freenrg_fep\"]\n",
    "    x_er = freenrg_df_pert_plotting_scatter[\"err_exp\"]\n",
    "    y_er = freenrg_df_pert_plotting_scatter[\"err_fep\"]\n",
    "\n",
    "    # plotting the scatterplot\n",
    "    scatterplot = [plt.scatter(x, y, zorder=10)]\n",
    "\n",
    "    #plotting error bars\n",
    "    plt.errorbar(x , y,\n",
    "                yerr=y_er,\n",
    "                # xerr=x_er,   # comment this line to hide experimental error bars \\\n",
    "                            # as this can sometimes overcrowd the plot.\n",
    "                ls=\"none\",\n",
    "                lw=0.5, \n",
    "                capsize=2,\n",
    "                color=\"black\",\n",
    "                zorder=5\n",
    "                )\n",
    "\n",
    "    # plot 1/2 kcal bounds:\n",
    "    plt.fill_between(\n",
    "                    x=[-100, 100], \n",
    "                    y2=[-100.25,99.75],\n",
    "                    y1=[-99.75, 100.25],\n",
    "                    lw=0, \n",
    "                    zorder=-10,\n",
    "                    alpha=0.3,\n",
    "                    color=\"grey\")\n",
    "    # upper bound:\n",
    "    plt.fill_between(\n",
    "                    x=[-100, 100], \n",
    "                    y2=[-99.5,100.5],\n",
    "                    y1=[-99.75, 100.25],\n",
    "                    lw=0, \n",
    "                    zorder=-10,\n",
    "                    color=\"grey\", \n",
    "                    alpha=0.2)\n",
    "    # lower bound:\n",
    "    plt.fill_between(\n",
    "                    x=[-100, 100], \n",
    "                    y2=[-100.25,99.75],\n",
    "                    y1=[-100.5, 99.5],\n",
    "                    lw=0, \n",
    "                    zorder=-10,\n",
    "                    color=\"grey\", \n",
    "                    alpha=0.2)\n",
    "\n",
    "    # get the bounds. This can be done with min/max or simply by hand.\n",
    "    all_freenrg_values = np.concatenate([freenrg_df_pert_plotting_scatter[\"freenrg_exp\"].values,freenrg_df_pert_plotting_scatter[\"freenrg_fep\"].values])\n",
    "    min_lim = min(all_freenrg_values)   \n",
    "    max_lim = max(all_freenrg_values)\n",
    "\n",
    "    # for a scatterplot we want the axis ranges to be the same. \n",
    "    plt.xlim(min_lim*1.3, max_lim*1.3)\n",
    "    plt.ylim(min_lim*1.3, max_lim*1.3)\n",
    "\n",
    "    plt.axhline(color=\"black\", zorder=1)\n",
    "    plt.axvline(color=\"black\", zorder=1)\n",
    "\n",
    "    plt.title(f\"Computed vs Experimental with {engine} and {file_ext_out.replace('_',',')}\")\n",
    "    plt.ylabel(\"Computed $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "    plt.xlabel(\"Experimental $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\n",
    "    plt.savefig(f\"{res_folder}/fep_vs_exp_scatterplot_pert_{file_ext_out}_{engine}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a bar graph\n",
    "# engine = [\"AMBER\"]\n",
    "\n",
    "for engine in engines:\n",
    "    # else, if want to substitute w 0 if it is the experimental values, eg for bar charts\n",
    "    # THIS DOES NOT WORK FOR SCATTER PLOTS - they will all be at 0, this is only useable for bar plots\n",
    "    freenrg_df_pert_plotting_bar = values_dict[engine][\"freenrg_df_pert\"].fillna(0)\n",
    "\n",
    "    # initiate an empty figure with fixed dimensions.\n",
    "    fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "    # determine positions for X axis labels.\n",
    "    x_locs = np.arange(len(freenrg_df_pert_plotting_bar))\n",
    "\n",
    "    # set bar width\n",
    "    width = 0.35  \n",
    "\n",
    "    # plot both our experimental and FEP free energies using an offset on the x position so bars don't overlap.\n",
    "    ax.bar(x_locs - width/2, height=freenrg_df_pert_plotting_bar[\"freenrg_exp\"], width=width, yerr=freenrg_df_pert_plotting_bar[\"err_exp\"],\n",
    "                    label='Experimental')\n",
    "    ax.bar(x_locs + width/2, height=freenrg_df_pert_plotting_bar[\"freenrg_fep\"], width=width, yerr=freenrg_df_pert_plotting_bar[\"err_fep\"],\n",
    "                    label='FEP')\n",
    "    \n",
    "    # format the plot further.\n",
    "    plt.axhline(color=\"black\")\n",
    "    plt.title(f\"Computed vs Experimental with {engine} and {file_ext_out.replace('_',',')}\")\n",
    "    plt.ylabel(\"$\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "    plt.xticks(x_locs, freenrg_df_pert_plotting_bar.index, rotation=70, ha=\"right\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f\"{res_folder}/fep_vs_exp_barplot_pert_{file_ext_out}_{engine}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_pert_df, mae_pert_df_err = calc_mae(values_dict, \"perts\")\n",
    "\n",
    "print(mae_pert_df)\n",
    "print(mae_pert_df_err)\n",
    "\n",
    "mae_pert_df.to_csv(f\"{res_folder}/mae_pert_{file_ext_out}.csv\", sep=\" \")\n",
    "mae_pert_df_err.to_csv(f\"{res_folder}/mae_pert_err_{file_ext_out}.csv\", sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from old\n",
    "\n",
    "# x = (np.array(x_data.iloc[0:len(x_data),1]))\n",
    "# y = np.array(y_data.iloc[0:len(y_data), 1])\n",
    "\n",
    "# #bootstrap to get measure of confidence intervals for these values\n",
    "# #make a df of the values\n",
    "# data_df = pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "# x = (data_df['x'].to_numpy()).reshape(-1,1)\n",
    "# y = data_df['y'].to_numpy()\n",
    "\n",
    "# #make the model and fit the data\n",
    "# model = LinearRegression().fit(x,y)\n",
    "# slope = model.coef_\n",
    "# intercept = model.intercept_\n",
    "# r_sq = model.score(x,y)\n",
    "# mue = (abs(data_df['y'] - data_df['x']).sum())/len(x_data)\n",
    "\n",
    "# # resample with replacement each row\n",
    "# boot_slopes = []\n",
    "# boot_interc = []\n",
    "# boot_r_sq = [] \n",
    "# boot_mues = []\n",
    "# #number of bootstrapping samples\n",
    "# n_boots = 1000\n",
    "\n",
    "# for n in range(n_boots):\n",
    "#     sample_df = data_df.sample(n=len(x_data), replace=True)\n",
    "#     # fit a linear regression\n",
    "#     x_temp = (sample_df['x'].to_numpy()).reshape(-1,1)\n",
    "#     y_temp = sample_df['y'].to_numpy()\n",
    "#     model_temp = LinearRegression().fit(x_temp,y_temp)\n",
    "#     slope_temp = model_temp.coef_\n",
    "#     intercept_temp = model_temp.intercept_\n",
    "#     r_sq_temp = model_temp.score(x_temp,y_temp) \n",
    "\n",
    "#     mue_temp = (abs(sample_df['y'] - sample_df['x']).sum())/len(x_data)\n",
    "\n",
    "#     # append coefficients\n",
    "#     boot_interc.append(intercept_temp)\n",
    "#     boot_slopes.append(slope_temp)\n",
    "#     boot_r_sq.append(r_sq_temp)\n",
    "#     boot_mues.append(mue_temp)\n",
    "\n",
    "# # #calculate the standard error for each\n",
    "# # slope_err = (np.std(boot_slopes))/(math.sqrt(n_boots))\n",
    "# # interc_err = (np.std(boot_interc))/(math.sqrt(n_boots))\n",
    "# # mue_err = (np.std(boot_mues))/(math.sqrt(n_boots))\n",
    "# # r_sq_err = (np.std(boot_r_sq))/(math.sqrt(n_boots))\n",
    "\n",
    "# #calculate the standard deviation which tbh seems like thats what it was doing in the one from loeffler for these\n",
    "# # deviation instead of the standard error\n",
    "# slope_err = (np.std(boot_slopes))\n",
    "# interc_err = (np.std(boot_interc))\n",
    "# mue_err = (np.std(boot_mues))\n",
    "# r_sq_err = (np.std(boot_r_sq))\n",
    "\n",
    "\n",
    "# #append data frame \n",
    "# equations = equations.append({'engine' : eng ,'slope' : slope, 'slope_err' : slope_err, \\\n",
    "#                               'intercept' : intercept, 'intercept_err' : interc_err, \\\n",
    "#                                 'r2' : r_sq, 'r2_err' : r_sq_err, \\\n",
    "#                                 'MUE': mue, 'MUE_err': mue_err}, ignore_index=True).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting multiple engines\n",
    "\n",
    "# plotting all together. Using the dictionaries saved before for plotting\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "colour = ['orange','orchid','darkturquoise','midnightblue']\n",
    "lines = []\n",
    "\n",
    "for eng,col in zip(engines,colour):\n",
    "\n",
    "    freenrg_df_pert_plotting_scatter = values_dict[eng][\"freenrg_df_pert\"].dropna()\n",
    "    x = freenrg_df_pert_plotting_scatter[\"freenrg_exp\"]\n",
    "    y = freenrg_df_pert_plotting_scatter[\"freenrg_fep\"]\n",
    "    x_er = freenrg_df_pert_plotting_scatter[\"err_exp\"]\n",
    "    y_er = freenrg_df_pert_plotting_scatter[\"err_fep\"]    \n",
    "\n",
    "    scatterplot = [plt.scatter(x, y, zorder=10, c=col)]    \n",
    "\n",
    "    # diff shapes for diff proteins\n",
    "    # scatterplot = [plt.scatter(x[:4], y[:4], zorder=10, c=col, label=\"TYK2\"),\n",
    "    #                plt.scatter(x[4:5], y[4:5], zorder=10, c=col, marker=\"D\", label=\"p38\"),\n",
    "    #                plt.scatter(x[5:], y[5:], zorder=10, c=col, marker=\"s\",label=\"MCL1\")]\n",
    "    lines += plt.plot(0,0,c=col, label=eng)\n",
    "\n",
    "    # x_er = np.array((eng_dict_plot_exp_for_eng[eng]).iloc[1:len(eng_dict_plot_exp_for_eng[eng]), 2])\n",
    "    plt.errorbar(x , y,\n",
    "                yerr=y_er,\n",
    "                # xerr=x_er,   # comment this line to hide experimental error bars \\\n",
    "                            # as this can sometimes overcrowd the plot.\n",
    "                ls=\"none\",\n",
    "                lw=0.5, \n",
    "                capsize=2,\n",
    "                color=\"black\",\n",
    "                zorder=5\n",
    "                )\n",
    "\n",
    "    #plotting lines - need to change this part so incl from the correct written equations if want a linear fit line\n",
    "    # x_line = np.linspace(-2,2,20)\n",
    "    # y_line = (slope)*(x_line) + (intercept)\n",
    "    # ax.plot(x_line, y_line, label=eng)\n",
    "\n",
    "labels = [l.get_label() for l in lines]\n",
    "plt.legend(lines, labels, loc='upper left')\n",
    "# plt.legend(scatterplot, [\"TYK2\",\"p38\",\"MCL1\"])\n",
    "\n",
    "# plot 1/2 kcal bounds:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-100.25,99.75],\n",
    "                y1=[-99.75, 100.25],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                alpha=0.3,\n",
    "                color=\"grey\")\n",
    "# upper bound:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-99.5,100.5],\n",
    "                y1=[-99.75, 100.25],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                color=\"grey\", \n",
    "                alpha=0.2)\n",
    "# lower bound:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-100.25,99.75],\n",
    "                y1=[-100.5, 99.5],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                color=\"grey\", \n",
    "                alpha=0.2)\n",
    "\n",
    "# get the bounds. This can be done with min/max or simply by hand.\n",
    "all_freenrg_values_pre = []\n",
    "for eng in engines:\n",
    "    x = np.array(freenrg_df_pert_plotting_scatter[\"freenrg_exp\"]).tolist()\n",
    "    y = np.array(freenrg_df_pert_plotting_scatter[\"freenrg_fep\"]).tolist()\n",
    "    all_freenrg_values_pre.append(x)\n",
    "    all_freenrg_values_pre.append(y)\n",
    "\n",
    "all_freenrg_values = []\n",
    "for sublist in all_freenrg_values_pre:\n",
    "    for item in sublist:\n",
    "        all_freenrg_values.append(item)\n",
    "\n",
    "min_lim = min(all_freenrg_values)   \n",
    "max_lim = max(all_freenrg_values)\n",
    "\n",
    "# for a scatterplot we want the axis ranges to be the same. \n",
    "plt.xlim(min_lim*1.3, max_lim*1.3)\n",
    "plt.ylim(min_lim*1.3, max_lim*1.3)\n",
    "\n",
    "plt.axhline(color=\"black\", zorder=1)\n",
    "plt.axvline(color=\"black\", zorder=1)\n",
    "\n",
    "#plt.xlabel('ΔΔG for experimental (kcal/mol)')\n",
    "#plt.ylabel('ΔΔG for calculated (kcal/mol)')\n",
    "# plt.title(f\"Computed vs Experimental FEP for {protein.upper()}, {file_ext_out.replace('_', ',')}\")\n",
    "plt.ylabel(\"Computed $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xlabel(\"Experimental $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "plt.savefig(f\"{res_folder}/fep_vs_exp_scatterplot_pert_{file_ext_out}_all.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting multiple engines\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "colour = ['darkturquoise','orange','orchid','midnightblue']\n",
    "# set bar width\n",
    "width = 0.15  \n",
    "placement = [-width*(3/2), -width*(1/2), width*(1/2), width*(3/2)]\n",
    "\n",
    "for eng,col,place in zip(engines,colour,placement):\n",
    "\n",
    "    freenrg_df_pert_plotting_bar = values_dict[eng][\"freenrg_df_pert\"].fillna(0)\n",
    "    x = freenrg_df_pert_plotting_bar[\"freenrg_exp\"]\n",
    "    y = freenrg_df_pert_plotting_bar[\"freenrg_fep\"]\n",
    "    x_er = freenrg_df_pert_plotting_bar[\"err_exp\"]\n",
    "    y_er = freenrg_df_pert_plotting_bar[\"err_fep\"]    \n",
    "\n",
    "    # determine positions for X axis labels.\n",
    "    x_locs = np.arange(len(freenrg_df_pert_plotting_bar))\n",
    "\n",
    "    # plot both our experimental and FEP free energies using an offset on the x position so bars don't overlap.\n",
    "\n",
    "    ax.bar(x_locs + place, height=freenrg_df_pert_plotting_bar[\"freenrg_fep\"], width=width, yerr=freenrg_df_pert_plotting_bar[\"err_fep\"],\n",
    "                    label=eng, color=col)\n",
    "\n",
    "# plot experimental\n",
    "ax.bar(x_locs + placement[-1], height=freenrg_df_pert_plotting_bar[\"freenrg_exp\"], width=width, yerr=freenrg_df_pert_plotting_bar[\"err_exp\"],\n",
    "                label='Experimental', color=colour[-1]) \n",
    "\n",
    "#plt.xlabel('ΔΔG for experimental (kcal/mol)')\n",
    "#plt.ylabel('ΔΔG for calculated (kcal/mol)')\n",
    "# format the plot further.\n",
    "plt.axhline(color=\"black\")\n",
    "plt.title(f\"Computed vs Experimental for {protein.upper()} and {file_ext_out.replace('_',',')}\")\n",
    "plt.ylabel(\"$\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xticks(x_locs, freenrg_df_pert_plotting_bar.index, rotation=70, ha=\"right\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"{res_folder}/fep_vs_exp_barplot_pert_{file_ext_out}_all.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freenrgworkflows for all engiens to populate values dict\n",
    "for eng in engines:\n",
    "    print(eng)\n",
    "    # using freenrg workflows\n",
    "    nA = networkanalysis.NetworkAnalyser()\n",
    "\n",
    "    first_file = False\n",
    "    for file_name in values_dict[eng][\"results_files\"]:\n",
    "        if first_file is False:\n",
    "            nA.read_perturbations_pandas(file_name, comments='#')\n",
    "            first_file = True\n",
    "        else:\n",
    "            # add more replicates to the graph. FreeNrgWorkflows will take care of averaging \n",
    "            # the free energies as well as propagating the error.\n",
    "            nA.add_data_to_graph_pandas(file_name)\n",
    "\n",
    "    computed_relative_DDGs = nA.freeEnergyInKcal\n",
    "    values_dict[eng][\"freenrgworkflows_ouput\"] = computed_relative_DDGs\n",
    "\n",
    "    # create a dictionary for the computed freenergworkflow values too\n",
    "    computed_val_dict = {}\n",
    "\n",
    "    # convert the list of dicitonaries from freenrgworkflows into a single dictionary\n",
    "    for lig_dict in computed_relative_DDGs:\n",
    "        lig_name = list(lig_dict.keys())[0]\n",
    "        comp = lig_dict[lig_name]\n",
    "        comp_err = lig_dict[\"error\"]\n",
    "        computed_val_dict.update({lig_name:(comp, comp_err)})\n",
    "\n",
    "    # add any ligands that are in the ligands file but dont have compimental values for\n",
    "    for lig_name in values_dict[eng][\"ligs\"]:\n",
    "        if lig_name in computed_val_dict:\n",
    "            pass\n",
    "        else:\n",
    "            computed_val_dict.update({lig_name:(None, None)})\n",
    "\n",
    "    # add to the dict\n",
    "    values_dict[eng][\"val_results\"] = computed_val_dict\n",
    "\n",
    "    freenrg_dict = {}\n",
    "\n",
    "    intermediate_string=\"\"\n",
    "\n",
    "    # construct dict with experimental freenrg and error.\n",
    "    for ligand in values_dict[\"experimental\"][\"val_results\"]:\n",
    "        # only consider the values for the ligands in this network\n",
    "        # if there is no value for the ligands in the experimental, this should be None from before\n",
    "        if ligand in values_dict[eng][\"ligs\"]:\n",
    "            freenrg = values_dict[\"experimental\"][\"val_results\"][ligand][0]\n",
    "            error = values_dict[\"experimental\"][\"val_results\"][ligand][1]\n",
    "            if intermediate_string != ligand:\n",
    "                freenrg_dict[ligand] = [freenrg, error]\n",
    "\n",
    "    # append computed freenrg and error.\n",
    "    for ligand in values_dict[eng][\"val_results\"]:\n",
    "        if ligand in values_dict[eng][\"ligs\"]:\n",
    "            freenrg = values_dict[eng][\"val_results\"][ligand][0]\n",
    "            error = values_dict[eng][\"val_results\"][ligand][1]\n",
    "            if intermediate_string != ligand:\n",
    "                freenrg_dict[ligand].append(freenrg)\n",
    "                freenrg_dict[ligand].append(error)\n",
    "\n",
    "    freenrg_df = pd.DataFrame(freenrg_dict, index=[\"freenrg_exp\", \"err_exp\", \"freenrg_fep\", \"err_fep\"]).transpose()\n",
    "    values_dict[eng][\"freenrg_df_val\"] = freenrg_df \n",
    "\n",
    "    # save our results to a file that can be opened in e.g. Excel.\n",
    "    freenrg_df.to_csv(f\"{res_folder}/fep_results_table_per_ligand_{file_ext_out}_{eng}.csv\")\n",
    "\n",
    "    del nA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot individual bar graphs for per ligand\n",
    "# engine = \"GROMACS\"\n",
    "\n",
    "for engine in engines:\n",
    "\tfreenrg_df_plotting_scatter = values_dict[engine][\"freenrg_df_val\"].dropna()\n",
    "\n",
    "\tplt.figure(figsize=(7,7))\n",
    "\n",
    "\tplt.scatter(freenrg_df_plotting_scatter[\"freenrg_exp\"], freenrg_df_plotting_scatter[\"freenrg_fep\"], zorder=10)\n",
    "\n",
    "\t# plot 1/2 kcal bounds:\n",
    "\tplt.fill_between(\n",
    "\t\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\t\ty2=[-100.25,99.75],\n",
    "\t\t\t\t\ty1=[-99.75, 100.25],\n",
    "\t\t\t\t\tlw=0, \n",
    "\t\t\t\t\tzorder=-10,\n",
    "\t\t\t\t\talpha=0.3,\n",
    "\t\t\t\t\tcolor=\"grey\")\n",
    "\t# upper bound:\n",
    "\tplt.fill_between(\n",
    "\t\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\t\ty2=[-99.5,100.5],\n",
    "\t\t\t\t\ty1=[-99.75, 100.25],\n",
    "\t\t\t\t\tlw=0, \n",
    "\t\t\t\t\tzorder=-10,\n",
    "\t\t\t\t\tcolor=\"grey\", \n",
    "\t\t\t\t\talpha=0.2)\n",
    "\t# lower bound:\n",
    "\tplt.fill_between(\n",
    "\t\t\t\t\tx=[-100, 100], \n",
    "\t\t\t\t\ty2=[-100.25,99.75],\n",
    "\t\t\t\t\ty1=[-100.5, 99.5],\n",
    "\t\t\t\t\tlw=0, \n",
    "\t\t\t\t\tzorder=-10,\n",
    "\t\t\t\t\tcolor=\"grey\", \n",
    "\t\t\t\t\talpha=0.2)\n",
    "\n",
    "\t# plot error bars:\n",
    "\tyerr = freenrg_df_plotting_scatter[\"err_fep\"]\n",
    "\txerr = freenrg_df_plotting_scatter[\"err_exp\"]\n",
    "\n",
    "\tplt.errorbar(freenrg_df_plotting_scatter[\"freenrg_exp\"], freenrg_df_plotting_scatter[\"freenrg_fep\"], \n",
    "\t\t\t\tyerr=yerr,\n",
    "\t\t\t\txerr=xerr,   # comment this line to hide experimental error bars \\\n",
    "\t\t\t\t\t\t\t# as this can sometimes overcrowd the plot.\n",
    "\t\t\t\tls=\"none\",\n",
    "\t\t\t\tlw=0.5, \n",
    "\t\t\t\tcapsize=2,\n",
    "\t\t\t\tcolor=\"black\",\n",
    "\t\t\t\tzorder=5\n",
    "\t\t\t\t)\n",
    "\n",
    "\t# format the plot further.\n",
    "\tplt.axhline(color=\"black\", zorder=1)\n",
    "\tplt.axvline(color=\"black\", zorder=1)\n",
    "\tplt.title(f\"Computed vs Experimental with {engine} and {file_ext_out.replace('_',',')}\")\n",
    "\tplt.ylabel(\"Predicted $\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\tplt.xlabel(\"Experimental $\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\n",
    "\t# get the bounds. This can be done with min/max or simply by hand.\n",
    "\tall_freenrg_values = np.concatenate([freenrg_df_plotting_scatter[\"freenrg_exp\"].values,freenrg_df_plotting_scatter[\"freenrg_fep\"].values])\n",
    "\tmin_lim = min(all_freenrg_values)\n",
    "\tmax_lim = max(all_freenrg_values)\n",
    "\n",
    "\t# for a scatterplot we want the axis ranges to be the same. \n",
    "\tplt.xlim(min_lim*1.3, max_lim*1.3)\n",
    "\tplt.ylim(min_lim*1.3, max_lim*1.3)\n",
    "\n",
    "\tplt.savefig(f\"{res_folder}/fep_vs_exp_scatterplot_val_{file_ext_out}_{engine}.png\", dpi=300, bbox_inches='tight')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot individual bar\n",
    "# engine = \"GROMACS\"\n",
    "\n",
    "for engine in engines:\n",
    "    \n",
    "    freenrg_df_plotting_bar = values_dict[engine][\"freenrg_df_val\"].fillna(0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "    # determine positions for X axis labels.\n",
    "    x_locs = np.arange(len(freenrg_df_plotting_bar))\n",
    "\n",
    "    # set bar width\n",
    "    width = 0.35  \n",
    "\n",
    "    # plot both our experimental and FEP free energies using an offset on the x position so bars don't overlap.\n",
    "    ax.bar(x_locs - width/2, height=freenrg_df_plotting_bar[\"freenrg_exp\"], width=width, yerr=freenrg_df_plotting_bar[\"err_exp\"],\n",
    "                    label='Experimental')\n",
    "    ax.bar(x_locs + width/2, height=freenrg_df_plotting_bar[\"freenrg_fep\"], width=width, yerr=freenrg_df_plotting_bar[\"err_fep\"],\n",
    "                    label='FEP')\n",
    "    \n",
    "    # format the plot further.\n",
    "    plt.axhline(color=\"black\")\n",
    "    plt.ylabel(\"$\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "    plt.xticks(x_locs, freenrg_df_plotting_bar.index, rotation=70, ha=\"right\")\n",
    "    plt.title(f\"Computed vs Experimental with {engine} and {file_ext_out.replace('_',',')}\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f\"{res_folder}/fep_vs_exp_barplot_val_{file_ext_out}_{engine}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all scatter per ligand\n",
    "\n",
    "# plotting multiple engines\n",
    "\n",
    "# plotting all together. Using the dictionaries saved before for plotting\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "colour = ['darkturquoise','orange','orchid','midnightblue']\n",
    "lines = []\n",
    "\n",
    "for eng,col in zip(engines,colour):\n",
    "\n",
    "    freenrg_df_plotting_scatter = values_dict[eng][\"freenrg_df_val\"].dropna()\n",
    "    x = freenrg_df_plotting_scatter[\"freenrg_exp\"]\n",
    "    y = freenrg_df_plotting_scatter[\"freenrg_fep\"]\n",
    "    x_er = freenrg_df_plotting_scatter[\"err_exp\"]\n",
    "    y_er = freenrg_df_plotting_scatter[\"err_fep\"]    \n",
    "\n",
    "    scatterplot = [plt.scatter(x, y, zorder=10, c=col)]    \n",
    "\n",
    "    # diff shapes for diff proteins\n",
    "    # scatterplot = [plt.scatter(x[:4], y[:4], zorder=10, c=col, label=\"TYK2\"),\n",
    "    #                plt.scatter(x[4:5], y[4:5], zorder=10, c=col, marker=\"D\", label=\"p38\"),\n",
    "    #                plt.scatter(x[5:], y[5:], zorder=10, c=col, marker=\"s\",label=\"MCL1\")]\n",
    "    lines += plt.plot(0,0,c=col, label=eng)\n",
    "\n",
    "    # x_er = np.array((eng_dict_plot_exp_for_eng[eng]).iloc[1:len(eng_dict_plot_exp_for_eng[eng]), 2])\n",
    "    plt.errorbar(x , y,\n",
    "                yerr=y_er,\n",
    "                xerr=x_er,   # comment this line to hide experimental error bars \\\n",
    "                            # as this can sometimes overcrowd the plot.\n",
    "                ls=\"none\",\n",
    "                lw=0.5, \n",
    "                capsize=2,\n",
    "                color=\"black\",\n",
    "                zorder=5\n",
    "                )\n",
    "\n",
    "    #plotting lines - need to change this part so incl from the correct written equations if want a linear fit line\n",
    "    # x_line = np.linspace(-2,2,20)\n",
    "    # y_line = (slope)*(x_line) + (intercept)\n",
    "    # ax.plot(x_line, y_line, label=eng)\n",
    "\n",
    "labels = [l.get_label() for l in lines]\n",
    "plt.legend(lines, labels, loc='upper left')\n",
    "# plt.legend(scatterplot, [\"TYK2\",\"p38\",\"MCL1\"])\n",
    "\n",
    "# plot 1/2 kcal bounds:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-100.25,99.75],\n",
    "                y1=[-99.75, 100.25],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                alpha=0.3,\n",
    "                color=\"grey\")\n",
    "# upper bound:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-99.5,100.5],\n",
    "                y1=[-99.75, 100.25],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                color=\"grey\", \n",
    "                alpha=0.2)\n",
    "# lower bound:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-100.25,99.75],\n",
    "                y1=[-100.5, 99.5],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                color=\"grey\", \n",
    "                alpha=0.2)\n",
    "\n",
    "# get the bounds. This can be done with min/max or simply by hand.\n",
    "all_freenrg_values_pre = []\n",
    "for eng in engines:\n",
    "    x = np.array(freenrg_df_pert_plotting_scatter[\"freenrg_exp\"]).tolist()\n",
    "    y = np.array(freenrg_df_pert_plotting_scatter[\"freenrg_fep\"]).tolist()\n",
    "    all_freenrg_values_pre.append(x)\n",
    "    all_freenrg_values_pre.append(y)\n",
    "\n",
    "all_freenrg_values = []\n",
    "for sublist in all_freenrg_values_pre:\n",
    "    for item in sublist:\n",
    "        all_freenrg_values.append(item)\n",
    "\n",
    "min_lim = min(all_freenrg_values)   \n",
    "max_lim = max(all_freenrg_values)\n",
    "\n",
    "# for a scatterplot we want the axis ranges to be the same. \n",
    "plt.xlim(min_lim*1.3, max_lim*1.3)\n",
    "plt.ylim(min_lim*1.3, max_lim*1.3)\n",
    "\n",
    "plt.axhline(color=\"black\", zorder=1)\n",
    "plt.axvline(color=\"black\", zorder=1)\n",
    "\n",
    "#plt.xlabel('ΔΔG for experimental (kcal/mol)')\n",
    "#plt.ylabel('ΔΔG for calculated (kcal/mol)')\n",
    "# plt.title(f\"Computed vs Experimental FEP for {protein.upper()}, {file_ext_out.replace('_', ' ')}\")\n",
    "plt.ylabel(\"Computed $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xlabel(\"Experimental $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"{res_folder}/fep_vs_exp_scatterplot_val_{file_ext_out}_all.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting multiple engines\n",
    "\n",
    "# plotting all together. Using the dictionaries saved before for plotting\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "colour = ['darkturquoise','orange','orchid','midnightblue']\n",
    "# set bar width\n",
    "width = 0.15  \n",
    "placement = [-width*(3/2), -width*(1/2), width*(1/2), width*(3/2)]\n",
    "\n",
    "for eng,col,place in zip(engines,colour,placement):\n",
    "\n",
    "    freenrg_df_pert_plotting_bar = values_dict[eng][\"freenrg_df_val\"].fillna(0)\n",
    "    x = freenrg_df_pert_plotting_bar[\"freenrg_exp\"]\n",
    "    y = freenrg_df_pert_plotting_bar[\"freenrg_fep\"]\n",
    "    x_er = freenrg_df_pert_plotting_bar[\"err_exp\"]\n",
    "    y_er = freenrg_df_pert_plotting_bar[\"err_fep\"]    \n",
    "\n",
    "    # determine positions for X axis labels.\n",
    "    x_locs = np.arange(len(freenrg_df_pert_plotting_bar))\n",
    "\n",
    "    # plot both our experimental and FEP free energies using an offset on the x position so bars don't overlap.\n",
    "\n",
    "    ax.bar(x_locs + place, height=freenrg_df_pert_plotting_bar[\"freenrg_fep\"], width=width, yerr=freenrg_df_pert_plotting_bar[\"err_fep\"],\n",
    "                    label=eng, color=col)\n",
    "\n",
    "# plot experimental\n",
    "ax.bar(x_locs + placement[-1], height=freenrg_df_pert_plotting_bar[\"freenrg_exp\"], width=width, yerr=freenrg_df_pert_plotting_bar[\"err_exp\"],\n",
    "                label='Experimental', color=colour[-1]) \n",
    "\n",
    "#plt.xlabel('ΔΔG for experimental (kcal/mol)')\n",
    "#plt.ylabel('ΔΔG for calculated (kcal/mol)')\n",
    "# format the plot further.\n",
    "plt.axhline(color=\"black\")\n",
    "plt.title(f\"Computed vs Experimental for {protein.upper()} and {file_ext_out.replace('_',',')}\")\n",
    "plt.ylabel(\"$\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xticks(x_locs, freenrg_df_pert_plotting_bar.index, rotation=70, ha=\"right\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"{res_folder}/fep_vs_exp_barplot_val_{file_ext_out}_all.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae for per ligand\n",
    "mae_pert_df, mae_pert_df_err = calc_mae(values_dict, \"ligs\")\n",
    "\n",
    "print(mae_pert_df)\n",
    "print(mae_pert_df_err)\n",
    "\n",
    "mae_pert_df.to_csv(f\"{res_folder}/mae_val_{file_ext_out}.csv\", sep=\" \")\n",
    "mae_pert_df_err.to_csv(f\"{res_folder}/mae_val_err_{file_ext_out}.csv\", sep=\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:teal\">Satistical analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine= \"GROMACS\"\n",
    "\n",
    "# _stats = stats.freeEnergyStats()\n",
    "# _stats.generate_statistics(values_dict[engine][\"freenrgworkflows_ouput\"],values_dict[\"experimental\"][\"freenrgworkflows_ouput\"],repeats=10000)\n",
    "# r_confidence = _stats.R_confidence\n",
    "# tau_confidence = _stats.tau_confidence\n",
    "# mue_confidence = _stats.mue_confidence\n",
    "# print (\"R confidence is:   %.2f < %.2f < %.2f\" %(r_confidence[1], r_confidence[0], r_confidence[2]))\n",
    "# print (\"MUE confidence is: %.2f < %.2f < %.2f\" %(mue_confidence[1], mue_confidence[0], mue_confidence[2]))\n",
    "# print (\"Tau confidence is: %.2f < %.2f < %.2f\" %(tau_confidence[1], tau_confidence[0], tau_confidence[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:teal\">Outliers</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_outliers_to_annotate = 5\n",
    "engine = \"GROMACS\"\n",
    "\n",
    "freenrg_df_plotting_scatter = values_dict[engine][\"freenrg_df_pert\"].dropna()\n",
    "\n",
    "x = freenrg_df_plotting_scatter[\"freenrg_exp\"]\n",
    "y = freenrg_df_plotting_scatter[\"freenrg_fep\"]\n",
    "x_er = freenrg_df_plotting_scatter[\"err_exp\"]\n",
    "y_er = freenrg_df_plotting_scatter[\"err_fep\"]    \n",
    "\n",
    "# get an array of the MUE values comparing experimental and FEP values. Take the absolute values.\n",
    "mue_values = abs(freenrg_df_plotting_scatter[\"freenrg_exp\"] - freenrg_df_plotting_scatter[\"freenrg_fep\"])\n",
    "\n",
    "# find the n ligand names that are outliers.\n",
    "outlier_names = mue_values.nlargest(number_outliers_to_annotate).index.values.tolist()\n",
    "print(outlier_names)\n",
    "\n",
    "# construct a list of labels to annotate the scatterplot with.\n",
    "annot_labels = []\n",
    "colours = []\n",
    "for ligand in freenrg_df_plotting_scatter.index.values:\n",
    "    # if the ligand is an outlier, append the name to the annotation labels list.\n",
    "    if ligand in outlier_names:\n",
    "        annot_labels.append(ligand)\n",
    "        colours.append(\"hotpink\")\n",
    "    else:\n",
    "        # if the ligand is not an outlier, append an empty string to the annotation labels list.\n",
    "        annot_labels.append(\"\")\n",
    "        colours.append(\"teal\")\n",
    "\n",
    "# Create the same scatterplot as above. Can include some more of the formatting if needed.\n",
    "plt.rc('font', size=12)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.scatter(x,y, zorder=10, c=colours)\n",
    "\n",
    "#plotting error bars\n",
    "plt.errorbar(x , y,\n",
    "            yerr=y_er,\n",
    "            # xerr=x_er,   # comment this line to hide experimental error bars \\\n",
    "                        # as this can sometimes overcrowd the plot.\n",
    "            ls=\"none\",\n",
    "            lw=0.5, \n",
    "            capsize=2,\n",
    "            color=\"black\",\n",
    "            zorder=5\n",
    "            )\n",
    "\n",
    "# get the bounds. This can be done with min/max or simply by hand.\n",
    "all_freenrg_values = np.concatenate([x.values,y.values])\n",
    "min_lim = min(all_freenrg_values)   \n",
    "max_lim = max(all_freenrg_values)\n",
    "\n",
    "# can plot a line for ideal\n",
    "# plt.plot((min_lim*1.3,max_lim*1.3),(min_lim*1.3,max_lim*1.3), color=\"teal\")\n",
    "\n",
    "# or if want to plot 1/2 kcal bounds\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-100.25,99.75],\n",
    "                y1=[-99.75, 100.25],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                alpha=0.3,\n",
    "                color=\"grey\")\n",
    "# upper bound:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-99.5,100.5],\n",
    "                y1=[-99.75, 100.25],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                color=\"grey\", \n",
    "                alpha=0.2)\n",
    "# lower bound:\n",
    "plt.fill_between(\n",
    "                x=[-100, 100], \n",
    "                y2=[-100.25,99.75],\n",
    "                y1=[-100.5, 99.5],\n",
    "                lw=0, \n",
    "                zorder=-10,\n",
    "                color=\"grey\", \n",
    "                alpha=0.2)\n",
    "\n",
    "# for a scatterplot we want the axis ranges to be the same. \n",
    "plt.xlim(min_lim*1.3, max_lim*1.3)\n",
    "plt.ylim(min_lim*1.3, max_lim*1.3)\n",
    "\n",
    "plt.axhline(color=\"black\", zorder=1)\n",
    "plt.axvline(color=\"black\", zorder=1)\n",
    "\n",
    "plt.ylabel(\"Computed $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xlabel(\"Experimental $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\n",
    "# then, after generating the figure, we can annotate:\n",
    "for i, txt in enumerate(annot_labels):\n",
    "    plt.annotate(txt, \n",
    "                 (freenrg_df_pert_plotting_scatter[\"freenrg_exp\"].values.tolist()[i]+0.1,     # x coords\n",
    "                  freenrg_df_pert_plotting_scatter[\"freenrg_fep\"].values.tolist()[i]+0.1),    # y coords\n",
    "                 size=15, color=\"hotpink\")\n",
    "\n",
    "# plt.savefig(\"analysis/fep_vs_exp_outlier_plot.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting convergence\n",
    "\n",
    "# tra=\"60~63\"\n",
    "# prot=\"mcl1\"\n",
    "# engine = ['AMBER','GROMACS','SOMD']\n",
    "# colour = ['orange','orchid','darkturquoise']\n",
    "\n",
    "# for leg in [ 'free', 'bound']:\n",
    "#     plt.figure()\n",
    "#     lines = []\n",
    "#     for eng,col in zip(engine,colour):\n",
    "#         with open (f'/home/anna/Documents/benchmark/{prot}/outputs/{eng}/{tra}/{leg}_pmf_{tra}_{eng}.pickle', 'rb') as handle:\n",
    "#             pmf_dict = pickle.load(handle)\n",
    "#         lines += plt.plot(0,0,c=col, label=eng)\n",
    "#         for repeat in pmf_dict:\n",
    "#             pmf = pmf_dict[repeat]\n",
    "#             x =[]\n",
    "#             y=[]\n",
    "#             for p in pmf:\n",
    "#                 x.append(p[0])\n",
    "#                 y.append(p[1]*(1/BSS.Units.Energy.kcal_per_mol))\n",
    "#             plt.plot(x,y,color=col)\n",
    "#     plt.xlim(xmin=0,xmax=1)\n",
    "#     plt.ylabel(\"Computed $\\Delta$G$_{transformation}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "#     plt.xlabel(\"Lambda\")\n",
    "#     labels = [l.get_label() for l in lines]\n",
    "#     plt.legend(lines, labels)\n",
    "#     plt.title(f\"Convergence, {leg} for {tra}\")\n",
    "#     plt.savefig(f'/home/anna/Documents/benchmark/{prot}/outputs/{eng}/{tra}/convergence_{leg}.png')\n",
    "\n",
    "# # plotting delta delta G\n",
    "\n",
    "# plt.figure()\n",
    "# lines = []\n",
    "# for eng,col in zip(engine,colour):\n",
    "#     with open (f'/home/anna/Documents/benchmark/{prot}/outputs/{eng}/{tra}/bound_pmf_{tra}_{eng}.pickle', 'rb') as handle:\n",
    "#         bound_pmf_dict = pickle.load(handle)\n",
    "#     with open (f'/home/anna/Documents/benchmark/{prot}/outputs/{eng}/{tra}/free_pmf_{tra}_{eng}.pickle', 'rb') as handle:\n",
    "#         free_pmf_dict = pickle.load(handle)\n",
    "#     lines += plt.plot(0,0,c=col, label=eng)\n",
    "#     for repf,repb in zip(free_pmf_dict,bound_pmf_dict):\n",
    "#         bound_pmf = bound_pmf_dict[repb]\n",
    "#         free_pmf = free_pmf_dict[repf]\n",
    "#         x = []\n",
    "#         y = []\n",
    "#         yerr = []\n",
    "#         for pb,pf in zip(bound_pmf,free_pmf):\n",
    "#             x.append(pb[0])\n",
    "#             y.append((pb[1]*(1/BSS.Units.Energy.kcal_per_mol))-(pf[1]*(1/BSS.Units.Energy.kcal_per_mol)))\n",
    "#             yerr.append((pb[2]*(1/BSS.Units.Energy.kcal_per_mol))+(pf[2]*(1/BSS.Units.Energy.kcal_per_mol)))\n",
    "#         plt.errorbar(x,y,yerr=yerr,color=col)\n",
    "# plt.xlim(xmin=0,xmax=1)\n",
    "# plt.ylabel(\"Computed $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "# plt.xlabel(\"Lambda\")\n",
    "# labels = [l.get_label() for l in lines]\n",
    "# plt.legend(lines, labels)\n",
    "# plt.title(f\"Convergence for {tra}\")\n",
    "# plt.savefig(f'/home/anna/Documents/benchmark/{prot}/outputs/{eng}/{tra}/convergence_deltadeltaG.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = ['AMBER','SOMD','GROMACS']\n",
    "# # trans = ['ejm42~ejm31','ejm42~ejm55','ejm54~ejm42','ejm55~ejm54','2w~2z','67~60','60~63']\n",
    "# trans = ['ejm55~ejm54']\n",
    "\n",
    "# colour = ['orange','orchid','darkturquoise','midnightblue']\n",
    "# colour_dict = {\"AMBER\":\"orange\",\"SOMD\":\"darkturquoise\",\"GROMACS\":\"orchid\",\"experimental\":\"midnightblue\"}\n",
    "# # plot the convergence w time\n",
    "# for tra in trans:\n",
    "#     prot = \"tyk2\"\n",
    "\n",
    "#     for leg in [ 'free','bound']:\n",
    "#         plt.figure()\n",
    "#         lines = []\n",
    "#         for eng,col in zip(engine,colour):\n",
    "#             # with open (f'/home/anna/Documents/benchmark/{prot}/outputs/{eng}/{tra}/{leg}_pmf_{tra}_{eng}.pickle', 'rb') as handle:\n",
    "#             with open (f'/home/anna/Documents/benchmark/{prot}/pickles/{leg}_pmf_{tra}_{eng}.pickle', 'rb') as handle:\n",
    "#                 pmf_dict = pickle.load(handle)\n",
    "#             lines += plt.plot(0,0,c=col, label=eng)\n",
    "#             for repeat in pmf_dict:\n",
    "#                 pmf = pmf_dict[repeat]\n",
    "#                 x =[]\n",
    "#                 y=[]\n",
    "#                 yerr = []\n",
    "#                 for p in pmf:\n",
    "#                     x.append(p[0])\n",
    "#                     y.append(p[1]*(1/BSS.Units.Energy.kcal_per_mol))\n",
    "#                     yerr.append(p[2]*(1/BSS.Units.Energy.kcal_per_mol))\n",
    "#                 plt.errorbar(x,y,yerr=yerr,color=col, ecolor='black')\n",
    "#         plt.xlim(xmin=0,xmax=1)\n",
    "#         plt.ylabel(\"Computed $\\Delta$G$_{transformation}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "#         plt.xlabel(\"Lambda\")\n",
    "#         labels = [l.get_label() for l in lines]\n",
    "#         plt.legend(lines, labels)\n",
    "#         plt.title(f\"Convergence, {leg} for {tra}\")\n",
    "#         plt.savefig(f'/home/anna/Documents/benchmark/{prot}/outputs/{eng}/{tra}/convergence_{leg}.png')\n",
    "\n",
    "#     # plotting delta delta G\n",
    "\n",
    "#     plt.figure()\n",
    "#     lines = []\n",
    "#     for eng in engine:\n",
    "#         # with open (f'/home/anna/Documents/benchmark/{prot}/outputs/{eng}/{tra}/bound_pmf_{tra}_{eng}.pickle', 'rb') as handle:\n",
    "#         with open (f'/home/anna/Documents/benchmark/{prot}/pickles/bound_pmf_{tra}_{eng}.pickle', 'rb') as handle:\n",
    "#             bound_pmf_dict = pickle.load(handle)\n",
    "#         # with open (f'/home/anna/Documents/benchmark/{prot}/outputs/{eng}/{tra}/free_pmf_{tra}_{eng}.pickle', 'rb') as handle:\n",
    "#         with open (f'/home/anna/Documents/benchmark/{prot}/pickles/free_pmf_{tra}_{eng}.pickle', 'rb') as handle:\n",
    "#             free_pmf_dict = pickle.load(handle)\n",
    "#         lines += plt.plot(0,0,c=colour_dict[eng], label=eng)\n",
    "#         for repf,repb in zip(free_pmf_dict,bound_pmf_dict):\n",
    "#             bound_pmf = bound_pmf_dict[repb]\n",
    "#             free_pmf = free_pmf_dict[repf]\n",
    "#             x = []\n",
    "#             y = []\n",
    "#             yerr = []\n",
    "#             for pb,pf in zip(bound_pmf,free_pmf):\n",
    "#                 x.append(pb[0])\n",
    "#                 y.append((pb[1]*(1/BSS.Units.Energy.kcal_per_mol))-(pf[1]*(1/BSS.Units.Energy.kcal_per_mol)))\n",
    "#                 yerr.append((pb[2]*(1/BSS.Units.Energy.kcal_per_mol))+(pf[2]*(1/BSS.Units.Energy.kcal_per_mol)))\n",
    "#             plt.errorbar(x,y,yerr=yerr,color=colour_dict[eng])\n",
    "#     plt.xlim(xmin=0,xmax=1)\n",
    "#     plt.ylabel(\"Computed $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "#     plt.xlabel(\"Lambda\")\n",
    "#     labels = [l.get_label() for l in lines]\n",
    "#     plt.legend(lines, labels)\n",
    "#     plt.title(f\"Convergence for {tra}\")\n",
    "#     plt.savefig(f'/home/anna/Documents/benchmark/{prot}/outputs/{eng}/{tra}/convergence_deltadeltaG.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can generate graph to visualise\n",
    "eng=\"SOMD\" # should be the same for each engine\n",
    "graph = gen_graph(values_dict[eng][\"ligs\"],values_dict[eng][\"perts\"],out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph)\n",
    "cycles = nx.cycle_basis(graph)\n",
    "print(cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all cycle closures\n",
    "cycle_closures = []\n",
    "\n",
    "for cycle in cycles:\n",
    "    length = len(cycle)\n",
    "    ligas = []\n",
    "    ligbs = []\n",
    "    for i in range(0, length-1):\n",
    "        ligas.append(cycle[i])\n",
    "        ligbs.append(cycle[i+1])\n",
    "    # add final cycle closure\n",
    "    ligas.append(cycle[-1])\n",
    "    ligbs.append(cycle[0])\n",
    "    # make list for cycle closure\n",
    "    cycle_closure = []\n",
    "    for liga, ligb in zip(ligas,ligbs):\n",
    "        cycle_closure.append(f\"{liga}~{ligb}\")\n",
    "    \n",
    "    cycle_closures.append(cycle_closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make into function and some way to write this into dict or df to add to overall dict\n",
    "\n",
    "for eng in engines:\n",
    "\n",
    "    cycles_dict = {}\n",
    "\n",
    "    # choose which df\n",
    "    pert_dict = values_dict[eng][\"pert_results\"]\n",
    "\n",
    "    cycle_vals = []\n",
    "\n",
    "    for cycle in cycle_closures:\n",
    "\n",
    "        cycle_dict = {}\n",
    "        # print(cycle)\n",
    "        cycle_val = []\n",
    "        cycle_val_err = []\n",
    "        for pert in cycle:\n",
    "\n",
    "            liga = pert.split(\"~\")[0]\n",
    "            ligb = pert.split(\"~\")[1]\n",
    "            rev_pert = f\"{ligb}~{liga}\"\n",
    "        \n",
    "            if pert in pert_dict:\n",
    "                if pert_dict[pert][0] is not None:\n",
    "                    cycle_val.append(+pert_dict[pert][0])\n",
    "                    cycle_val_err.append(pert_dict[pert][1])\n",
    "                else:\n",
    "                    print(f\"{pert} or {rev_pert} does not exist in the results for {cycle} for {eng}. This cycle is not included.\")\n",
    "                    break\n",
    "            elif rev_pert in pert_dict:\n",
    "                if pert_dict[rev_pert][0] is not None:\n",
    "                    cycle_val.append(-pert_dict[rev_pert][0])\n",
    "                    cycle_val_err.append(pert_dict[rev_pert][1])\n",
    "                else:\n",
    "                    print(f\"{pert} or {rev_pert} does not exist in the results for {cycle} for {eng}. This cycle is not included.\")\n",
    "                    break\n",
    "\n",
    "        if not all(i is None for i in cycle_val):\n",
    "            cycle_vals.append(sum(cycle_val))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    print(f\"{eng} cycle vals is {cycle_vals}\")\n",
    "    print(f\"{eng} cycle mean is {np.mean(cycle_vals)}\")\n",
    "    print(f\"{eng} cycle deviation is {np.std(cycle_vals)}\")\n",
    "\n",
    "    values_dict[eng][\"cycle_closures\"] = (cycles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cinnabar import wrangle,plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in engines:\n",
    "    convert_cinnabar_file(values_dict[eng][\"results_files\"], values_dict[\"experimental\"][\"val_results\"], f\"{res_folder}/{cinnabar_file}_{eng}\")\n",
    "\n",
    "    network = wrangle.FEMap(f\"{res_folder}/{cinnabar_file}_{eng}.csv\")\n",
    "    # plot the perturbations\n",
    "    plotting.plot_DDGs(network.graph, filename=f\"{res_folder}/DDGs_{file_ext_out}_{eng}.png\", title=f\"DDGs_{protein}_{file_ext_out}_{eng}\")\n",
    "    #plot the ligands\n",
    "    plotting.plot_DGs(network.graph, filename=f\"{res_folder}/DGs_{file_ext_out}_{eng}.png\", title=f\"DGs_{protein}_{file_ext_out}_{eng}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('biosimspace-dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d79bb85316fa6c998e385cc39903e056bffeb3f6098416e9c269ddd32175e919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
