{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:teal\">RBFE Network Setup</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import BioSimSpace as BSS\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all the folder locations\n",
    "protein = \"p38\"\n",
    "main_folder = \"/home/anna/Documents/benchmark\"\n",
    "\n",
    "# for sem perturbations\n",
    "tgt_to_run = f\"{protein}_rename\" #f\"{protein}_me\" f\"{protein}_rename\" for tyk2 and p38\n",
    "cats_files_path = f\"{main_folder}/scripts/RBFENN/ANALYSIS/perturbation_networks/output/series_predictions\"\n",
    "\n",
    "# other folders\n",
    "system_folder = f\"{main_folder}/{protein}_benchmark\"\n",
    "scripts_folder = f\"{main_folder}/scripts\" # scripts should be located in here\n",
    "input_dir = f\"{main_folder}/inputs\"\n",
    "path_to_ligands = f\"{input_dir}/{protein}/ligands\"\n",
    "exec_folder = f\"{system_folder}/execution_model\"\n",
    "\n",
    "folder_list = [system_folder, exec_folder]\n",
    "for fold in folder_list:\n",
    "    if not os.path.isdir(fold):\n",
    "        os.mkdir(fold)\n",
    "        print(f\"Made dir {fold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSS.Notebook.View(f\"{input_dir}/{protein}/protein/{protein}_parameterised.pdb\").system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:teal\">2. Setting up the Network</span>\n",
    "<a id=\"setup\"></a>\n",
    "\n",
    "##### <span style=\"color:teal\">Choosing the parameters for the FEP runs</span>\n",
    "<a id=\"parameters\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodes to pick things\n",
    "node = BSS.Gateway.Node(\"A node to create input files for molecular dynamics simulation.\")\n",
    "\n",
    "node.addInput(\"Ligand FF\", BSS.Gateway.String(help=\"Force field to parameterise ligands with.\",\n",
    "                                             allowed=[\"GAFF2\", \"Parsely\", \"Sage\"],\n",
    "                                             default=\"Sage\"))\n",
    "\n",
    "node.addInput(\"Protein FF\", BSS.Gateway.String(help=\"Force field to parameterise the protein with.\",\n",
    "                                             allowed=[\"FF03\", \"FF14SB\", \"FF99\", \"FF99SB\", \"FF99SBILDN\"],\n",
    "                                             default=\"FF14SB\"))\n",
    "\n",
    "node.addInput(\"Water Model\", BSS.Gateway.String(help=\"Water model to use.\",\n",
    "                                             allowed=[\"SPC\", \"SPCE\", \"TIP3P\", \"TIP4P\", \"TIP5P\"],\n",
    "                                             default=\"TIP3P\"))\n",
    "\n",
    "node.addInput(\"Box Edges\", BSS.Gateway.String(help=\"Size of water box around molecular system.\",\n",
    "                                             allowed=[\"20*angstrom\", \"25*angstrom\", \"30*angstrom\", \"35*angstrom\", \"45*angstrom\", \"5*nm\", \"7*nm\", \"10*nm\"],\n",
    "                                             default=\"30*angstrom\"))\n",
    "\n",
    "node.addInput(\"Box Shape\", BSS.Gateway.String(help=\"Geometric shape of water box.\",\n",
    "                                             allowed=[\"cubic\", \"truncatedOctahedron\"],\n",
    "                                             default=\"truncatedOctahedron\"))\n",
    "\n",
    "node.addInput(\"Run Time\", BSS.Gateway.String(help=\"The sampling time per lambda window.\",\n",
    "                                             allowed=[\"10*ps\", \"100*ps\", \"1*ns\", \"2*ns\", \"3*ns\", \"4*ns\", \"5*ns\", \"8*ns\", \"10*ns\", \"12*ns\", \"15*ns\"],\n",
    "                                             default=\"4*ns\"))\n",
    "\n",
    "node.addInput(\"HMR\", BSS.Gateway.String(help=\"Whether or not Hydrogen Mass repartitioning should be used. If true, a timestep of 4 fs will be used.\",\n",
    "                                             allowed=[\"True\",\"False\"],\n",
    "                                             default=\"True\"))\n",
    "\n",
    "engines_options = [e.upper() for e in BSS.FreeEnergy.engines()]\n",
    "engines_options.append(\"ALL\")\n",
    "\n",
    "node.addInput(\"FEP Engine\", BSS.Gateway.String(help=\"Engine to run FEP with. BSS available engines, or ALL.\",\n",
    "                                             allowed=engines_options,\n",
    "                                             default=\"ALL\"))\n",
    "\n",
    "node.addInput(\"LambdaWindows\", BSS.Gateway.String(help=\"The number of lambda windows for regular transformations.\",\n",
    "                                             allowed=[\"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\"],\n",
    "                                             default=\"11\"))\n",
    "\n",
    "# node.addInput(\"DiffLambdaWindows\", BSS.Gateway.String(help=\"The number of lambda windows for difficult transformations.\",\n",
    "#                                              allowed=[\"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\"],\n",
    "#                                              default=\"17\"))\n",
    "                                             \n",
    "# node.addInput(\"LOMAP Threshold\", BSS.Gateway.String(help=\"The LOMAP score threshold to define difficult transformations.\",\n",
    "#                                              allowed=[\"0.1\", \"0.2\", \"0.3\", \"0.4\", \"0.5\", \"0.6\", \"0.7\", \"0.8\", \"0.9\"],\n",
    "#                                              default=\"0.4\"))\n",
    "\n",
    "node.addInput(\"Number of repeats\", BSS.Gateway.String(help=\"The number of repeats of the simulation.\",\n",
    "                                             allowed=[str(i) for i in range (1,11)],\n",
    "                                             default=str(3)))\n",
    "\n",
    "node.addInput(\"Keep trajectories\", BSS.Gateway.String(help=\"Whether to keep the trajectory files or not.\",\n",
    "                                             allowed=[\"None\",\"0,0.5,1\", \"0,1\", \"All\"],\n",
    "                                             default=\"0,0.5,1\"))\n",
    "\n",
    "node.showControls()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:teal\">The FEP Network</span>  \n",
    "<a id=\"perts\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate transformation network based on ligands\n",
    "ligand_files = sorted(glob.glob(f\"{path_to_ligands}/*.sdf\"))\n",
    "\n",
    "ligands = []\n",
    "ligand_names = []\n",
    "\n",
    "for filepath in ligand_files:\n",
    "    # append the molecule object to a list.\n",
    "    ligands.append(BSS.IO.readMolecules(filepath)[0])\n",
    "    \n",
    "    # append the molecule name to another list so that we can use the name of each molecule in our workflow.\n",
    "    ligand_names.append(filepath.split(\"/\")[-1].replace(\".sdf\",\"\"))\n",
    "\n",
    "print(ligand_names)\n",
    "print(len(ligand_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if wanna remove certain ligands\n",
    "# ligs_remove_list = ['lig_ejm51', 'lig_ejm52', 'lig_ejm53']\n",
    "\n",
    "# for index, lig in enumerate(ligand_names):\n",
    "#     if lig in ligs_remove_list:\n",
    "#         ligand_names.remove(lig)\n",
    "#         del ligands[index]\n",
    "\n",
    "# print(ligand_names)\n",
    "# print(len(ligand_names))\n",
    "# print(len(ligands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations, lomap_scores = BSS.Align.generateNetwork(ligands, plot_network=True, names=ligand_names, work_dir=f\"{exec_folder}/visualise_network_lomap\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of perts\n",
    "pert_network_dict = {}\n",
    "transformations_named = [(ligand_names[transf[0]], ligand_names[transf[1]]) for transf in transformations]\n",
    "for score, transf in sorted(zip(lomap_scores, transformations_named)):\n",
    "    pert_network_dict[transf] = score\n",
    "    print(transf, score)\n",
    "\n",
    "# for t, s in sorted(zip(transformations_named, lomap_scores), key=lambda x: x[1]):\n",
    "#     print(f\"({ligand_names[t[0]]}, {ligand_names[t[1]]}), {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # alternatively, if we want to recalculate the LOMAP score for this perturbation:\n",
    "# # if we consider the ligands list, we can use the index of the ligands we want to add an edge for.\n",
    "# # first we need to choose our ligands.\n",
    "# lig_a = \"ejm48\"\n",
    "# lig_b = \"ejm51\"\n",
    "\n",
    "# # then, we need to find this index for our chosen edge that we are adding.\n",
    "# lig_a_index = ligand_names.index(lig_a)\n",
    "# lig_b_index = ligand_names.index(lig_b)\n",
    "# # finally, we need to calculate this single lomap score.\n",
    "# single_transformation, single_lomap_score = BSS.Align.generateNetwork([ligands[lig_a_index], ligands[lig_b_index]], names=[ligand_names[lig_a_index], ligand_names[lig_b_index]], plot_network=False)\n",
    "# print(f\"LOMAP score for {lig_a} to {lig_b} is {single_lomap_score[0]} .\")\n",
    "# pert_network_dict[(lig_a, lig_b)] = single_lomap_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # answer\n",
    "# for key in [('ejm42', 'ejm54'), ('ejm31', 'ejm45')]:\n",
    "#     del pert_network_dict[key]\n",
    "# # both the lowest scores are with ejm54, however if we remove these ejm54 won't be connected anymore, so we will remove\n",
    "# # the next lowest perturbation instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have made these changes to the network, we want to visualise it again. We can do this using NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the graph.\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Loop over the nligands and add as nodes to the graph.\n",
    "for lig in ligand_names:\n",
    "    graph.add_node(lig, label=lig, labelloc=\"t\")\n",
    "\n",
    "# Loop over the edges in the dictionary and add to the graph.\n",
    "for edge in pert_network_dict:\n",
    "    graph.add_edge(edge[0],edge[1],\n",
    "                    label=(pert_network_dict[edge]))\n",
    "\n",
    "# Plot the networkX graph.\n",
    "pos = nx.kamada_kawai_layout(graph)\n",
    "plt.figure(figsize=(14,14), dpi=150)\n",
    "nx.draw(\n",
    "    graph, pos, edge_color='black', width=1, linewidths=1,\n",
    "    node_size=1500, node_color='skyblue', font_size = 12,\n",
    "    labels={node: node for node in graph.nodes()})\n",
    "\n",
    "nx.draw_networkx_edge_labels(\n",
    "    graph, pos,\n",
    "    edge_labels=pert_network_dict,\n",
    "    font_color='purple', font_size=10)\n",
    "\n",
    "plt.savefig(f\"{exec_folder}/adjusted_lomap_network.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adding an intermediate\n",
    "# #generate transformation network based on ligands\n",
    "# ligand_files_list = glob.glob(f\"{path_to_ligands}/*.sdf\")\n",
    "# ligand_files_list.append(f\"{path_to_ligands}/intermediate/intermediate_H.sdf\")\n",
    "# ligand_files = sorted(ligand_files_list)\n",
    "\n",
    "# ligands = []\n",
    "# ligand_names = []\n",
    "\n",
    "# for filepath in ligand_files:\n",
    "#     # append the molecule object to a list.\n",
    "#     ligands.append(BSS.IO.readMolecules(filepath)[0])\n",
    "    \n",
    "#     # append the molecule name to another list so that we can use the name of each molecule in our workflow.\n",
    "#     ligand_names.append(filepath.split(\"/\")[-1].replace(\".sdf\",\"\"))\n",
    "\n",
    "# transformations, lomap_scores = BSS.Align.generateNetwork(ligands, plot_network=True, names=ligand_names)\n",
    "\n",
    "# pert_network_dict = {}\n",
    "# transformations_named = [(ligand_names[transf[0]], ligand_names[transf[1]]) for transf in transformations]\n",
    "# for score, transf in sorted(zip(lomap_scores, transformations_named)):\n",
    "#     pert_network_dict[transf] = score\n",
    "#     print(transf, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dict for lomap to a file\n",
    "\n",
    "with open(f\"{exec_folder}/network_lomap_scores.dat\", \"w\") as scores_file:\n",
    "    writer = csv.writer(scores_file)\n",
    "\n",
    "    for score, transf in sorted(zip(lomap_scores, transformations_named)):\n",
    "        pert_network_dict[transf] = score\n",
    "        writer.writerow([transf[0], transf[1], score])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:teal\">Preparing for the FEP pipeline</span>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write ligands file.\n",
    "with open(f\"{exec_folder}/ligands.dat\", \"w\") as ligands_file:\n",
    "    writer = csv.writer(ligands_file)\n",
    "    for lig in ligand_names:\n",
    "        writer.writerow([lig])\n",
    "\n",
    "# create protocol. \n",
    "protocol = [\n",
    "    f\"ligand forcefield = {node.getInput('Ligand FF')}\",\n",
    "    f\"protein forcefield = {node.getInput('Protein FF')}\",\n",
    "    f\"solvent = {node.getInput('Water Model')}\",\n",
    "    f\"box edges = {node.getInput('Box Edges')}\",\n",
    "    f\"box type = {node.getInput('Box Shape')}\",\n",
    "    f\"protocol = default\", # can remove this line? need to change all script lines too\n",
    "    f\"sampling = {node.getInput('Run Time')}\",\n",
    "    f\"HMR = {node.getInput('HMR')}\",\n",
    "    f\"repeats = {node.getInput('Number of repeats')}\",\n",
    "    f\"keep trajectories = {node.getInput('Keep trajectories')}\",\n",
    "]\n",
    "\n",
    "\n",
    "# write protocol to file.\n",
    "with open(f\"{exec_folder}/protocol.dat\", \"w\") as protocol_file:\n",
    "    writer = csv.writer(protocol_file)\n",
    "\n",
    "    for prot_line in protocol:\n",
    "        \n",
    "        writer.writerow([prot_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write perts file. Base the lambda schedule on the file generated in the previous cell.\n",
    "np.set_printoptions(formatter={'float': '{: .4f}'.format})\n",
    "\n",
    "# from protocol, derive the engine we want to use on the cluster.\n",
    "engine = node.getInput('FEP Engine').upper()\n",
    "\n",
    "with open(f\"{exec_folder}/network_lomap.dat\", \"w\") as network_file:\n",
    "\n",
    "    writer = csv.writer(network_file, delimiter=\" \")\n",
    "    \n",
    "    for pert, lomap_score in pert_network_dict.items():\n",
    "        # # based on the provided (at top of notebook) lambda allocations and LOMAP threshold, decide allocation.\n",
    "        # if lomap_score == None or lomap_score < float(node.getInput(\"LOMAP Threshold\")):\n",
    "        #     num_lambda = node.getInput(\"DiffLambdaWindows\")\n",
    "        # else:\n",
    "        #     num_lambda = node.getInput(\"LambdaWindows\")\n",
    "        \n",
    "        num_lambda = node.getInput(\"LambdaWindows\") # same no lamdda windows for all\n",
    "       \n",
    "        # given the number of allocated lambda windows, generate an array for parsing downstream.\n",
    "        lam_array_np = np.around(np.linspace(0, 1, int(num_lambda)), decimals=5)\n",
    "\n",
    "        # make the array into a format readable by bash.\n",
    "        lam_array = str(lam_array_np).replace(\"[ \", \"\").replace(\"]\", \"\").replace(\"  \", \",\").replace('\\n', '')\n",
    "\n",
    "        # write out both directions for this perturbation.\n",
    "        if engine == \"ALL\":\n",
    "            for eng in BSS.FreeEnergy.engines():\n",
    "                writer.writerow([pert[0], pert[1], len(lam_array_np), lam_array, eng])\n",
    "        else:\n",
    "            writer.writerow([pert[0], pert[1], len(lam_array_np), lam_array, engine])\n",
    "        # writer.writerow([pert[1], pert[0], len(lam_array_np), lam_array, engine])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:teal\">Generating the RBFENN</span>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleArray(arr):\n",
    "    \"\"\"Scales an array to be the inverse in the range [0-1].\"\"\"\n",
    "    \n",
    "    # normalise to the range 0-1.\n",
    "    return minmax_scale(1 /  arr, feature_range=(0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the FEPNN SEM prediction per ligand.\n",
    "perts = {}\n",
    "for cats_file in glob.glob(f\"{cats_files_path}/{tgt_to_run}_*\"):\n",
    "    \n",
    "    with open(cats_file, \"r\") as readfile:\n",
    "        reader = csv.reader(readfile)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            pert = row[0]\n",
    "            pred_sem = float(row[1])\n",
    "            \n",
    "            if not pert in perts:\n",
    "                perts[pert] = [pred_sem]\n",
    "            else:\n",
    "                perts[pert].append(pred_sem)\n",
    "            \n",
    "# compute the mean SEM prediction per pert.\n",
    "pert_names = []\n",
    "pert_sems = []\n",
    "for pert, sems in perts.items():\n",
    "    mean_sem = np.mean(sems)\n",
    "    pert_names.append(pert)\n",
    "    pert_sems.append(float(mean_sem))\n",
    "\n",
    "# now scale the sems to [0-1].\n",
    "pert_sems = scaleArray(np.array(pert_sems))\n",
    "\n",
    "for pert, val in zip(pert_names, pert_sems):\n",
    "    perts[pert] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "written = []\n",
    "with open(f\"{exec_folder}/links_file.in\", \"w\") as writefile:\n",
    "    writer = csv.writer(writefile, delimiter =\" \")\n",
    "    \n",
    "    for pert_name, value in perts.items():\n",
    "        # find the lomap filename for both ligs.\n",
    "        liga_lomap_name = None\n",
    "        ligb_lomap_name = None\n",
    "        for filename in glob.glob(f\"{path_to_ligands}/*.sdf\"):\n",
    "            # if \"lig_8\" in filename:\n",
    "            #     continue # exclude +1 ligands from tnks2 set.\n",
    "            if pert_name.split(\"~\")[0] in filename:\n",
    "                liga_lomap_name = filename.split(\"/\")[-1].split(\".\")[0]#.replace(\"ejm\",\"ejm_\").replace(\"jmc\",\"jmc_\")\n",
    "            elif pert_name.split(\"~\")[1] in filename:\n",
    "                ligb_lomap_name = filename.split(\"/\")[-1].split(\".\")[0]#.replace(\"ejm\",\"ejm_\").replace(\"jmc\",\"jmc_\")\n",
    "            \n",
    "            if liga_lomap_name and ligb_lomap_name:\n",
    "                if not [liga_lomap_name, ligb_lomap_name] in written:\n",
    "                    writer.writerow([liga_lomap_name, ligb_lomap_name, value])\n",
    "                    \n",
    "                    written.append([liga_lomap_name, ligb_lomap_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ligands and ligands_names already exists due to lomap above\n",
    "\n",
    "transformations_fepnn, rbfenn_scores = BSS.Align.generateNetwork(ligands, plot_network=True, names=ligand_names, \n",
    "                                                         work_dir=f\"{exec_folder}/visualise_network_rbfenn\",\n",
    "                                                         links_file=f\"{exec_folder}/links_file.in\"\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of perts rbfenn\n",
    "rbfenn_pert_network_dict = {}\n",
    "transformations_named_rbfenn = [(ligand_names[transf[0]], ligand_names[transf[1]]) for transf in transformations_fepnn]\n",
    "for score, transf in sorted(zip(rbfenn_scores, transformations_named_rbfenn)):\n",
    "    rbfenn_pert_network_dict[transf] = score\n",
    "    print(transf, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the rbfenn to a different network file\n",
    "\n",
    "with open(f\"{exec_folder}/network_rbfenn.dat\", \"w\") as network_file:\n",
    "\n",
    "    writer = csv.writer(network_file, delimiter=\" \")\n",
    "    \n",
    "    for pert, rbfenn_score in rbfenn_pert_network_dict.items():\n",
    "        # # based on the provided (at top of notebook) lambda allocations and LOMAP threshold, decide allocation.\n",
    "        # if rbfenn_score == None or rbfenn_score < float(node.getInput(\"LOMAP Threshold\")):\n",
    "        #     num_lambda = node.getInput(\"DiffLambdaWindows\")\n",
    "        # else:\n",
    "        #     num_lambda = node.getInput(\"LambdaWindows\")\n",
    "\n",
    "        num_lambda = node.getInput(\"LambdaWindows\") \n",
    "       \n",
    "        # given the number of allocated lambda windows, generate an array for parsing downstream.\n",
    "        lam_array_np = np.around(np.linspace(0, 1, int(num_lambda)), decimals=5)\n",
    "\n",
    "        # make the array into a format readable by bash.\n",
    "        lam_array = str(lam_array_np).replace(\"[ \", \"\").replace(\"]\", \"\").replace(\"  \", \",\").replace('\\n', '')\n",
    "\n",
    "        # write out both directions for this perturbation.\n",
    "        if engine == \"ALL\":\n",
    "            for eng in BSS.FreeEnergy.engines():\n",
    "                writer.writerow([pert[0], pert[1], len(lam_array_np), lam_array, eng])\n",
    "        else:\n",
    "            writer.writerow([pert[0], pert[1], len(lam_array_np), lam_array, engine])\n",
    "        # writer.writerow([pert[1], pert[0], len(lam_array_np), lam_array, engine])         \n",
    "\n",
    "# write the dict for lomap to a file\n",
    "\n",
    "with open(f\"{exec_folder}/network_rbfenn_scores.dat\", \"w\") as scores_file:\n",
    "    writer = csv.writer(scores_file)\n",
    "\n",
    "    for score, transf in sorted(zip(rbfenn_scores, transformations_named_rbfenn)):\n",
    "        rbfenn_pert_network_dict[transf] = score\n",
    "        writer.writerow([transf[0], transf[1], score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the graph.\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Loop over the nligands and add as nodes to the graph.\n",
    "for lig in ligand_names:\n",
    "    graph.add_node(lig, label=lig, labelloc=\"t\")\n",
    "\n",
    "# Loop over the edges in the dictionary and add to the graph.\n",
    "for edge in rbfenn_pert_network_dict:\n",
    "    graph.add_edge(edge[0],edge[1],\n",
    "                    label=(rbfenn_pert_network_dict[edge]))\n",
    "\n",
    "# Plot the networkX graph.\n",
    "pos = nx.kamada_kawai_layout(graph)\n",
    "plt.figure(figsize=(14,14), dpi=150)\n",
    "nx.draw(\n",
    "    graph, pos, edge_color='black', width=1, linewidths=1,\n",
    "    node_size=1500, node_color='skyblue', font_size = 12,\n",
    "    labels={node: node for node in graph.nodes()})\n",
    "\n",
    "nx.draw_networkx_edge_labels(\n",
    "    graph, pos,\n",
    "    edge_labels=rbfenn_pert_network_dict,\n",
    "    font_color='purple', font_size=10)\n",
    "\n",
    "plt.savefig(f\"{exec_folder}/adjusted_rbfenn_network.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:teal\">Comparing lomap and the rbfenn</span>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the perts in each and all together\n",
    "perts_lomap = []\n",
    "perts_rbfenn = []\n",
    "perts = []\n",
    "\n",
    "with open(f\"{exec_folder}/network_rbfenn_scores.dat\", \"r\") as fepnn_file, \\\n",
    "        open(f\"{exec_folder}/network_lomap_scores.dat\", \"r\") as lomap_file:\n",
    "    reader_fepnn = csv.reader(fepnn_file)\n",
    "    reader_lomap = csv.reader(lomap_file)\n",
    "    \n",
    "    for line in reader_fepnn:\n",
    "        perts_rbfenn.append(f\"{line[0]}~{line[1]}\")\n",
    "        perts.append(f\"{line[0]}~{line[1]}\")\n",
    "    for line in reader_lomap:\n",
    "        perts_lomap.append(f\"{line[0]}~{line[1]}\")\n",
    "        perts.append(f\"{line[0]}~{line[1]}\")\n",
    "\n",
    "# write a file that contains the combined perts, directions are distinct     \n",
    "combined_perts = []\n",
    "filtered_out = 0\n",
    "for pert in perts:\n",
    "    \n",
    "    if not pert in combined_perts:\n",
    "        combined_perts.append(pert)\n",
    "    else:\n",
    "        filtered_out += 1\n",
    "print(f\"Removed {filtered_out} duplicate perts between lomap and rbfenn to give {len(combined_perts)} combined perts.\")\n",
    "\n",
    "# write a file that contains the unique perts, 1 direction only.      \n",
    "filtered_perts = []\n",
    "filtered_out = 0\n",
    "for pert in combined_perts:\n",
    "    \n",
    "    inv_pert = pert.split(\"~\")[1]+\"~\"+pert.split(\"~\")[0]\n",
    "    \n",
    "    if not pert in filtered_perts and not inv_pert in filtered_perts:\n",
    "        filtered_perts.append(pert)\n",
    "    else:\n",
    "        filtered_out += 1\n",
    "print(f\"Removed {filtered_out} inverse perts to give {len(filtered_perts)} unique perts, one direction only.\")\n",
    "\n",
    "# get the perts that are unique to each\n",
    "unique_perts = []\n",
    "unique_out_lomap = 0\n",
    "unique_out_rbfenn = 0\n",
    "shared_out = 0\n",
    "\n",
    "for pert in perts_lomap:\n",
    "    \n",
    "    inv_pert = pert.split(\"~\")[1]+\"~\"+pert.split(\"~\")[0]\n",
    "    \n",
    "    if not pert in perts_rbfenn and not inv_pert in perts_rbfenn:\n",
    "        unique_perts.append((pert, \"lomap\"))\n",
    "        unique_out_lomap += 1\n",
    "\n",
    "for pert in perts_rbfenn:\n",
    "    \n",
    "    inv_pert = pert.split(\"~\")[1]+\"~\"+pert.split(\"~\")[0]\n",
    "    \n",
    "    if not pert in perts_lomap and not inv_pert in perts_lomap:\n",
    "        unique_perts.append((pert, \"rbfenn\"))\n",
    "        unique_out_rbfenn += 1\n",
    "    \n",
    "for pert in combined_perts:\n",
    "\n",
    "    inv_pert = pert.split(\"~\")[1]+\"~\"+pert.split(\"~\")[0]\n",
    "\n",
    "    if pert in perts_lomap or inv_pert in perts_lomap:\n",
    "        if pert in perts_rbfenn or inv_pert in perts_rbfenn:\n",
    "            unique_perts.append((pert, \"shared\"))\n",
    "            shared_out += 1\n",
    "\n",
    "       \n",
    "print(f\"There are {unique_out_lomap} pert(s) unique to lomap and {unique_out_rbfenn} pert(s) unique to rbfenn.\")\n",
    "print(f\"There are {shared_out} pert(s) shared between lomap and rbfenn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{exec_folder}/combined_perts.dat\", \"w\") as writefile:\n",
    "    writer = csv.writer(writefile)\n",
    "    for pert in combined_perts:\n",
    "        writer.writerow([pert])\n",
    "print(f\"Total number of combined perturbations: {len(combined_perts)}\")\n",
    "\n",
    "with open(f\"{exec_folder}/filtered_perts.dat\", \"w\") as writefile:\n",
    "    writer = csv.writer(writefile)\n",
    "    for pert in filtered_perts:\n",
    "        writer.writerow([pert])\n",
    "print(f\"Total number of filtered perturbations: {len(filtered_perts)}\")\n",
    "\n",
    "# write a file for the different perts\n",
    "with open(f\"{exec_folder}/unique_perts.dat\", \"w\") as writefile:\n",
    "    writer = csv.writer(writefile)\n",
    "    for pert in unique_perts:\n",
    "        writer.writerow([pert[0],pert[1]])\n",
    "print(f\"Total number of unique perturbations: {len(unique_perts)} (lomap: {unique_out_lomap}, rbfenn: {unique_out_rbfenn})\")\n",
    "print(f\"Total number of shared perturbations: {shared_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dicitonary of the perts for plotting the nx graph\n",
    "both_pert_networks_dict = {}\n",
    "\n",
    "for pert in filtered_perts:\n",
    "\n",
    "    inv_pert = pert.split(\"~\")[1]+\"~\"+pert.split(\"~\")[0]\n",
    "    \n",
    "    if pert in perts_lomap and pert in perts_rbfenn:\n",
    "        both_pert_networks_dict[pert] = \"both\"\n",
    "    elif inv_pert in perts_lomap and pert in perts_rbfenn:\n",
    "        both_pert_networks_dict[pert] = \"both\"\n",
    "    elif pert in perts_lomap and pert not in perts_rbfenn:\n",
    "        both_pert_networks_dict[pert] = \"lomap\"\n",
    "    elif inv_pert in perts_lomap and pert not in perts_rbfenn:\n",
    "        both_pert_networks_dict[pert] = \"lomap\"\n",
    "    elif pert not in perts_lomap and pert in perts_rbfenn:\n",
    "        both_pert_networks_dict[pert] = \"rbfenn\"\n",
    "    elif inv_pert not in perts_lomap and pert in perts_rbfenn:\n",
    "        both_pert_networks_dict[pert] = \"rbfenn\"      \n",
    "\n",
    "# create dict for images for the nx graph\n",
    "image_dict = {}\n",
    "# list files in inputs\n",
    "input_files_for_image = sorted(os.listdir(f\"{exec_folder}/visualise_network_lomap/inputs\"))\n",
    "for in_file in input_files_for_image:\n",
    "    lig_name_list = in_file.split(\"_\")[1:]\n",
    "    lig_name = '_'.join(lig_name_list).split(\".\")[0]\n",
    "    lig_number = in_file.split(\"_\")[0]\n",
    "    image_dict[lig_name] = lig_number   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_pert_networks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the graph.\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Loop over the nligands and add as nodes to the graph.\n",
    "for lig in ligand_names:\n",
    "    img = f\"{exec_folder}/visualise_network_lomap/images/{image_dict[lig]}.png\"\n",
    "    graph.add_node(lig, image=img, label=lig, labelloc=\"t\")\n",
    "\n",
    "# make a dict of colours\n",
    "# navy teal  #CC00CC\n",
    "# clear is '#FF000000' \n",
    "colour_dict = {\"both\":'navy' ,\"lomap\":'teal' ,\"rbfenn\":'hotpink' }\n",
    "\n",
    "# Loop over the edges in the dictionary and add to the graph.\n",
    "for edge in both_pert_networks_dict:\n",
    "    graph.add_edge(edge.split(\"~\")[0],edge.split(\"~\")[1],\n",
    "                    color=colour_dict[both_pert_networks_dict[edge]]\n",
    "                    )\n",
    "\n",
    "# Plot the networkX graph.\n",
    "pos = nx.kamada_kawai_layout(graph)\n",
    "colours = nx.get_edge_attributes(graph,'color').values()\n",
    "\n",
    "plt.figure(figsize=(12,12), dpi=150)\n",
    "nx.draw(\n",
    "    graph, pos, edge_color=colours, width=1, linewidths=5,\n",
    "    node_size=2000, node_color='skyblue', font_size = 12,\n",
    "    labels={node: node for node in graph.nodes()})\n",
    "\n",
    "plt.savefig(f\"{exec_folder}/compared_networks_no_images.png\", dpi=300)\n",
    "# plt.show()\n",
    "\n",
    "# Convert to a dot graph.\n",
    "dot_graph = nx.drawing.nx_pydot.to_pydot(graph)\n",
    "\n",
    "# Write to a PNG.\n",
    "network_plot = f\"{exec_folder}/compared_networks.png\"\n",
    "dot_graph.write_png(network_plot)\n",
    "\n",
    "# Create a plot of the network.\n",
    "img = mpimg.imread(network_plot)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the lomap score for the combined network file (unfiltered)\n",
    "combined_pert_network_dict = {}\n",
    "\n",
    "for pert in combined_perts:\n",
    "    lig_a = pert.split(\"~\")[0]\n",
    "    lig_b = pert.split(\"~\")[1]\n",
    "    # then, we need to find this index for our chosen edge that we are adding.\n",
    "    lig_a_index = ligand_names.index(lig_a)\n",
    "    lig_b_index = ligand_names.index(lig_b)\n",
    "    # finally, we need to calculate this single lomap score.\n",
    "    single_transformation, single_lomap_score = BSS.Align.generateNetwork([ligands[lig_a_index], ligands[lig_b_index]], names=[ligand_names[lig_a_index], ligand_names[lig_b_index]], plot_network=False)\n",
    "    print(f\"LOMAP score for {lig_a} to {lig_b} is {single_lomap_score[0]} .\")\n",
    "    combined_pert_network_dict[(lig_a, lig_b)] = single_lomap_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the combined to a different network file\n",
    "\n",
    "with open(f\"{exec_folder}/network_combined.dat\", \"w\") as network_file:\n",
    "\n",
    "    writer = csv.writer(network_file, delimiter=\" \")\n",
    "    \n",
    "    for pert, score in combined_pert_network_dict.items():\n",
    "        # # based on the provided (at top of notebook) lambda allocations and LOMAP threshold, decide allocation.\n",
    "        # if score == None or score < float(node.getInput(\"LOMAP Threshold\")):\n",
    "        #     num_lambda = node.getInput(\"DiffLambdaWindows\")\n",
    "        # else:\n",
    "        #     num_lambda = node.getInput(\"LambdaWindows\")\n",
    "        \n",
    "        num_lambda = node.getInput(\"LambdaWindows\")            \n",
    "       \n",
    "        # given the number of allocated lambda windows, generate an array for parsing downstream.\n",
    "        lam_array_np = np.around(np.linspace(0, 1, int(num_lambda)), decimals=5)\n",
    "\n",
    "        # make the array into a format readable by bash.\n",
    "        lam_array = str(lam_array_np).replace(\"[ \", \"\").replace(\"]\", \"\").replace(\"  \", \",\").replace('\\n', '')\n",
    "\n",
    "        # write out both directions for this perturbation.\n",
    "        if engine == \"ALL\":\n",
    "            for eng in BSS.FreeEnergy.engines():\n",
    "                writer.writerow([pert[0], pert[1], len(lam_array_np), lam_array, eng])\n",
    "        else:\n",
    "            writer.writerow([pert[0], pert[1], len(lam_array_np), lam_array, engine])\n",
    "        # writer.writerow([pert[1], pert[0], len(lam_array_np), lam_array, engine])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d79bb85316fa6c998e385cc39903e056bffeb3f6098416e9c269ddd32175e919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
